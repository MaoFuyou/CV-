{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#我之前已经下载好了！\n",
    "my_alexnet = torchvision.models.alexnet()\n",
    "my_alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "my_fault = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914,0.4822,0.4465],[0.247,0.243,0.261])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dateset = torchvision.datasets.CIFAR10(root = 'E:',train = True,transform = my_fault,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dateset = torchvision.datasets.CIFAR10(root = 'E:',train = False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dateset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dateset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 随机显示图片\n",
    "\n",
    "a = np.random.randint(0,len(train_dateset))\n",
    "img = train_dateset.data[a]\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#dataloader的目的是用来 调节batch_size的作用\n",
    "# next数据！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset= train_dateset,batch_size=16 ,shuffle= True)\n",
    "test_dataloader = DataLoader(dataset=test_dateset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: E:\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
       "           )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for param in my_alexnet.parameters():\n",
    "    print(type(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in my_alexnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "#重新构建 最后一层！！\n",
    "in_f = my_alexnet.classifier[6].in_features\n",
    "print(in_f)\n",
    "my_alexnet.classifier[6] = nn.Linear(in_f,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.001\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(my_alexnet.classifier[6].parameters(),lr = learn_rate,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n",
      "True\n",
      "11.6\n",
      "8302\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.is_available())\n",
    "print(torch.cuda_version)\n",
    "print(torch.backends.cudnn.version())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "current loss = 2.3045814037323\n",
      "current loss = 2.3046414852142334\n",
      "current loss = 2.298905611038208\n",
      "current loss = 2.3045010566711426\n",
      "current loss = 2.297875165939331\n",
      "current loss = 2.3037571907043457\n",
      "current loss = 2.304687023162842\n",
      "current loss = 2.299530029296875\n",
      "current loss = 2.303954839706421\n",
      "current loss = 2.300779104232788\n",
      "current loss = 2.2985761165618896\n",
      "current loss = 2.3038246631622314\n",
      "current loss = 2.300067663192749\n",
      "current loss = 2.303713798522949\n",
      "current loss = 2.3022537231445312\n",
      "current loss = 2.2991037368774414\n",
      "current loss = 2.3032984733581543\n",
      "current loss = 2.302204132080078\n",
      "current loss = 2.3038887977600098\n",
      "current loss = 2.3025588989257812\n",
      "current loss = 2.3062057495117188\n",
      "current loss = 2.3001952171325684\n",
      "current loss = 2.2979576587677\n",
      "current loss = 2.298529624938965\n",
      "current loss = 2.3026084899902344\n",
      "current loss = 2.304960012435913\n",
      "current loss = 2.303532123565674\n",
      "current loss = 2.308176040649414\n",
      "current loss = 2.3024802207946777\n",
      "current loss = 2.300305128097534\n",
      "current loss = 2.300180435180664\n",
      "current loss = 2.3017659187316895\n",
      "current loss = 2.307234525680542\n",
      "current loss = 2.3036084175109863\n",
      "current loss = 2.299079179763794\n",
      "current loss = 2.3069615364074707\n",
      "current loss = 2.301219940185547\n",
      "current loss = 2.304889440536499\n",
      "current loss = 2.30389666557312\n",
      "current loss = 2.3031888008117676\n",
      "current loss = 2.298746347427368\n",
      "current loss = 2.3026163578033447\n",
      "current loss = 2.303903341293335\n",
      "current loss = 2.3065972328186035\n",
      "current loss = 2.29514217376709\n",
      "current loss = 2.30454683303833\n",
      "current loss = 2.3032920360565186\n",
      "current loss = 2.300015926361084\n",
      "current loss = 2.3070244789123535\n",
      "current loss = 2.302915573120117\n",
      "current loss = 2.3012523651123047\n",
      "current loss = 2.303466558456421\n",
      "current loss = 2.29872465133667\n",
      "current loss = 2.3011090755462646\n",
      "current loss = 2.3014094829559326\n",
      "current loss = 2.3020853996276855\n",
      "current loss = 2.3040311336517334\n",
      "current loss = 2.3103644847869873\n",
      "current loss = 2.3049261569976807\n",
      "current loss = 2.305774688720703\n",
      "current loss = 2.3033668994903564\n",
      "current loss = 2.3034603595733643\n",
      "current loss = 2.30363392829895\n",
      "current loss = 2.3057236671447754\n",
      "current loss = 2.305529832839966\n",
      "current loss = 2.3026325702667236\n",
      "current loss = 2.3018572330474854\n",
      "current loss = 2.3026955127716064\n",
      "current loss = 2.302292823791504\n",
      "current loss = 2.3046135902404785\n",
      "current loss = 2.305466651916504\n",
      "current loss = 2.3036091327667236\n",
      "current loss = 2.301787853240967\n",
      "current loss = 2.3034698963165283\n",
      "current loss = 2.299811601638794\n",
      "current loss = 2.303290605545044\n",
      "current loss = 2.302615165710449\n",
      "current loss = 2.300023317337036\n",
      "current loss = 2.3016786575317383\n",
      "current loss = 2.3039662837982178\n",
      "current loss = 2.300607204437256\n",
      "current loss = 2.304274797439575\n",
      "current loss = 2.3026797771453857\n",
      "current loss = 2.3011252880096436\n",
      "current loss = 2.3035387992858887\n",
      "current loss = 2.3049161434173584\n",
      "current loss = 2.30541729927063\n",
      "current loss = 2.30532169342041\n",
      "current loss = 2.301027774810791\n",
      "current loss = 2.301666021347046\n",
      "current loss = 2.3052172660827637\n",
      "current loss = 2.301481246948242\n",
      "current loss = 2.300569772720337\n",
      "current loss = 2.2935497760772705\n",
      "current loss = 2.3016719818115234\n",
      "current loss = 2.299487590789795\n",
      "current loss = 2.303999423980713\n",
      "current loss = 2.301723003387451\n",
      "current loss = 2.304996967315674\n",
      "current loss = 2.301889657974243\n",
      "current loss = 2.3049752712249756\n",
      "current loss = 2.3014676570892334\n",
      "current loss = 2.303849458694458\n",
      "current loss = 2.3039398193359375\n",
      "current loss = 2.3008780479431152\n",
      "current loss = 2.3047935962677\n",
      "current loss = 2.3038182258605957\n",
      "current loss = 2.3023643493652344\n",
      "current loss = 2.302442789077759\n",
      "current loss = 2.303786516189575\n",
      "current loss = 2.3017451763153076\n",
      "current loss = 2.3010451793670654\n",
      "current loss = 2.3037986755371094\n",
      "current loss = 2.3052875995635986\n",
      "current loss = 2.3049817085266113\n",
      "current loss = 2.3073484897613525\n",
      "current loss = 2.3001978397369385\n",
      "current loss = 2.300215244293213\n",
      "current loss = 2.3034584522247314\n",
      "current loss = 2.300955057144165\n",
      "current loss = 2.3031296730041504\n",
      "current loss = 2.304551124572754\n",
      "current loss = 2.2985761165618896\n",
      "current loss = 2.303539276123047\n",
      "current loss = 2.3037235736846924\n",
      "current loss = 2.304842948913574\n",
      "current loss = 2.3038246631622314\n",
      "current loss = 2.3021769523620605\n",
      "current loss = 2.2992701530456543\n",
      "current loss = 2.298293113708496\n",
      "current loss = 2.3010454177856445\n",
      "current loss = 2.300875425338745\n",
      "current loss = 2.3043854236602783\n",
      "current loss = 2.3027701377868652\n",
      "current loss = 2.30065655708313\n",
      "current loss = 2.3046133518218994\n",
      "current loss = 2.300934076309204\n",
      "current loss = 2.3067312240600586\n",
      "current loss = 2.2984113693237305\n",
      "current loss = 2.3021695613861084\n",
      "current loss = 2.301849603652954\n",
      "current loss = 2.302278995513916\n",
      "current loss = 2.301920175552368\n",
      "current loss = 2.301027297973633\n",
      "current loss = 2.3023829460144043\n",
      "current loss = 2.3024866580963135\n",
      "current loss = 2.302935838699341\n",
      "current loss = 2.302363634109497\n",
      "current loss = 2.3034305572509766\n",
      "current loss = 2.3017525672912598\n",
      "current loss = 2.302640914916992\n",
      "current loss = 2.301551580429077\n",
      "current loss = 2.3028318881988525\n",
      "current loss = 2.3001468181610107\n",
      "current loss = 2.305429458618164\n",
      "current loss = 2.2999463081359863\n",
      "current loss = 2.2993950843811035\n",
      "current loss = 2.3027639389038086\n",
      "current loss = 2.2976269721984863\n",
      "current loss = 2.301812171936035\n",
      "current loss = 2.3022568225860596\n",
      "current loss = 2.3014349937438965\n",
      "current loss = 2.3024356365203857\n",
      "current loss = 2.306722402572632\n",
      "current loss = 2.3006012439727783\n",
      "current loss = 2.3033864498138428\n",
      "current loss = 2.300771474838257\n",
      "current loss = 2.2983202934265137\n",
      "current loss = 2.2984259128570557\n",
      "current loss = 2.307612180709839\n",
      "current loss = 2.3015832901000977\n",
      "current loss = 2.3020124435424805\n",
      "current loss = 2.3039004802703857\n",
      "current loss = 2.2989659309387207\n",
      "current loss = 2.3029401302337646\n",
      "current loss = 2.30117130279541\n",
      "current loss = 2.311418056488037\n",
      "current loss = 2.306403160095215\n",
      "current loss = 2.3081743717193604\n",
      "current loss = 2.3077263832092285\n",
      "current loss = 2.3033978939056396\n",
      "current loss = 2.3013365268707275\n",
      "current loss = 2.300934314727783\n",
      "current loss = 2.3050484657287598\n",
      "current loss = 2.3015835285186768\n",
      "current loss = 2.2966349124908447\n",
      "current loss = 2.3001456260681152\n",
      "current loss = 2.306532859802246\n",
      "current loss = 2.3020308017730713\n",
      "current loss = 2.3027799129486084\n",
      "current loss = 2.302079677581787\n",
      "current loss = 2.3011953830718994\n",
      "current loss = 2.3043575286865234\n",
      "current loss = 2.303712844848633\n",
      "current loss = 2.3027613162994385\n",
      "current loss = 2.303436040878296\n",
      "current loss = 2.304633378982544\n",
      "current loss = 2.3064606189727783\n",
      "current loss = 2.2981176376342773\n",
      "current loss = 2.3017539978027344\n",
      "current loss = 2.3018181324005127\n",
      "current loss = 2.2994253635406494\n",
      "current loss = 2.302842140197754\n",
      "current loss = 2.305661916732788\n",
      "current loss = 2.307945966720581\n",
      "current loss = 2.3066303730010986\n",
      "current loss = 2.3043770790100098\n",
      "current loss = 2.304698944091797\n",
      "current loss = 2.303849220275879\n",
      "current loss = 2.2953133583068848\n",
      "current loss = 2.30173921585083\n",
      "current loss = 2.3012773990631104\n",
      "current loss = 2.301870107650757\n",
      "current loss = 2.3023316860198975\n",
      "current loss = 2.304159641265869\n",
      "current loss = 2.3006694316864014\n",
      "current loss = 2.3039021492004395\n",
      "current loss = 2.302137613296509\n",
      "current loss = 2.305468797683716\n",
      "current loss = 2.305593490600586\n",
      "current loss = 2.3051676750183105\n",
      "current loss = 2.305760145187378\n",
      "current loss = 2.299537420272827\n",
      "current loss = 2.30503249168396\n",
      "current loss = 2.3026766777038574\n",
      "current loss = 2.299781084060669\n",
      "current loss = 2.304830551147461\n",
      "current loss = 2.300575017929077\n",
      "current loss = 2.2984182834625244\n",
      "current loss = 2.3024327754974365\n",
      "current loss = 2.3065388202667236\n",
      "current loss = 2.305614709854126\n",
      "current loss = 2.30659818649292\n",
      "current loss = 2.301508903503418\n",
      "current loss = 2.306853771209717\n",
      "current loss = 2.301598072052002\n",
      "current loss = 2.303773880004883\n",
      "current loss = 2.301168441772461\n",
      "current loss = 2.3043718338012695\n",
      "current loss = 2.2989320755004883\n",
      "current loss = 2.3003249168395996\n",
      "current loss = 2.304659128189087\n",
      "current loss = 2.301678419113159\n",
      "current loss = 2.3011550903320312\n",
      "current loss = 2.301842212677002\n",
      "current loss = 2.3018863201141357\n",
      "current loss = 2.30009126663208\n",
      "current loss = 2.303453207015991\n",
      "current loss = 2.298769950866699\n",
      "current loss = 2.301874876022339\n",
      "current loss = 2.30433988571167\n",
      "current loss = 2.3019003868103027\n",
      "current loss = 2.3096749782562256\n",
      "current loss = 2.3034238815307617\n",
      "current loss = 2.3020198345184326\n",
      "current loss = 2.3059260845184326\n",
      "current loss = 2.3048112392425537\n",
      "current loss = 2.2979326248168945\n",
      "current loss = 2.3029909133911133\n",
      "current loss = 2.303447961807251\n",
      "current loss = 2.3035888671875\n",
      "current loss = 2.301053524017334\n",
      "current loss = 2.303271770477295\n",
      "current loss = 2.3019587993621826\n",
      "current loss = 2.30124831199646\n",
      "current loss = 2.3026506900787354\n",
      "current loss = 2.30122447013855\n",
      "current loss = 2.306811809539795\n",
      "current loss = 2.3023993968963623\n",
      "current loss = 2.3022444248199463\n",
      "current loss = 2.3042140007019043\n",
      "current loss = 2.3038394451141357\n",
      "current loss = 2.3001668453216553\n",
      "current loss = 2.29803729057312\n",
      "current loss = 2.3009653091430664\n",
      "current loss = 2.3044185638427734\n",
      "current loss = 2.301774024963379\n",
      "current loss = 2.304440498352051\n",
      "current loss = 2.3042869567871094\n",
      "current loss = 2.3015215396881104\n",
      "current loss = 2.3031797409057617\n",
      "current loss = 2.301177501678467\n",
      "current loss = 2.3026158809661865\n",
      "current loss = 2.301454782485962\n",
      "current loss = 2.3022749423980713\n",
      "current loss = 2.3025567531585693\n",
      "current loss = 2.300950527191162\n",
      "current loss = 2.304309606552124\n",
      "current loss = 2.3028335571289062\n",
      "current loss = 2.3045902252197266\n",
      "current loss = 2.3012306690216064\n",
      "current loss = 2.305065631866455\n",
      "current loss = 2.299335479736328\n",
      "current loss = 2.3042914867401123\n",
      "current loss = 2.301959991455078\n",
      "current loss = 2.3044540882110596\n",
      "current loss = 2.3008127212524414\n",
      "current loss = 2.303018808364868\n",
      "current loss = 2.3045692443847656\n",
      "current loss = 2.3075942993164062\n",
      "current loss = 2.301363706588745\n",
      "current loss = 2.3012375831604004\n",
      "current loss = 2.3024208545684814\n",
      "current loss = 2.3044092655181885\n",
      "current loss = 2.29947566986084\n",
      "current loss = 2.3031647205352783\n",
      "current loss = 2.3041703701019287\n",
      "current loss = 2.3026371002197266\n",
      "current loss = 2.3041489124298096\n",
      "current loss = 2.2991039752960205\n",
      "current loss = 2.3046321868896484\n",
      "current loss = 2.3007619380950928\n",
      "current loss = 2.3012356758117676\n",
      "current loss = 2.3039255142211914\n",
      "current loss = 2.3062195777893066\n",
      "current loss = 2.3035531044006348\n",
      "current loss = 2.2998080253601074\n",
      "current loss = 2.3048136234283447\n",
      "current loss = 2.301085948944092\n",
      "current loss = 2.302208423614502\n",
      "current loss = 2.3012008666992188\n",
      "current loss = 2.3050918579101562\n",
      "current loss = 2.305098056793213\n",
      "current loss = 2.2988455295562744\n",
      "current loss = 2.302189826965332\n",
      "current loss = 2.302349805831909\n",
      "current loss = 2.303145170211792\n",
      "current loss = 2.305447816848755\n",
      "current loss = 2.2950451374053955\n",
      "current loss = 2.3053104877471924\n",
      "current loss = 2.307830333709717\n",
      "current loss = 2.3025662899017334\n",
      "current loss = 2.301180839538574\n",
      "current loss = 2.302180290222168\n",
      "current loss = 2.300647258758545\n",
      "current loss = 2.303372859954834\n",
      "current loss = 2.300407886505127\n",
      "current loss = 2.299177885055542\n",
      "current loss = 2.3010263442993164\n",
      "current loss = 2.30100417137146\n",
      "current loss = 2.298511028289795\n",
      "current loss = 2.3015315532684326\n",
      "current loss = 2.2989065647125244\n",
      "current loss = 2.300379991531372\n",
      "current loss = 2.3028268814086914\n",
      "current loss = 2.3085131645202637\n",
      "current loss = 2.302058219909668\n",
      "current loss = 2.3022494316101074\n",
      "current loss = 2.305072784423828\n",
      "current loss = 2.3021113872528076\n",
      "current loss = 2.305717706680298\n",
      "current loss = 2.2995100021362305\n",
      "current loss = 2.3004207611083984\n",
      "current loss = 2.3095521926879883\n",
      "current loss = 2.3010427951812744\n",
      "current loss = 2.2976012229919434\n",
      "current loss = 2.299701690673828\n",
      "current loss = 2.2987112998962402\n",
      "current loss = 2.303699493408203\n",
      "current loss = 2.3055472373962402\n",
      "current loss = 2.3042216300964355\n",
      "current loss = 2.3017077445983887\n",
      "current loss = 2.299553632736206\n",
      "current loss = 2.3076798915863037\n",
      "current loss = 2.3002679347991943\n",
      "current loss = 2.3059983253479004\n",
      "current loss = 2.306929111480713\n",
      "current loss = 2.303321599960327\n",
      "current loss = 2.3066444396972656\n",
      "current loss = 2.2985634803771973\n",
      "current loss = 2.306833028793335\n",
      "current loss = 2.297581195831299\n",
      "current loss = 2.3048911094665527\n",
      "current loss = 2.3031842708587646\n",
      "current loss = 2.301175594329834\n",
      "current loss = 2.3028833866119385\n",
      "current loss = 2.3043627738952637\n",
      "current loss = 2.3045480251312256\n",
      "current loss = 2.304152011871338\n",
      "current loss = 2.301100254058838\n",
      "current loss = 2.3047196865081787\n",
      "current loss = 2.3043227195739746\n",
      "current loss = 2.301366090774536\n",
      "current loss = 2.299501657485962\n",
      "current loss = 2.3005104064941406\n",
      "current loss = 2.3029801845550537\n",
      "current loss = 2.3029720783233643\n",
      "current loss = 2.3006153106689453\n",
      "current loss = 2.296896457672119\n",
      "current loss = 2.307699203491211\n",
      "current loss = 2.2998738288879395\n",
      "current loss = 2.3041419982910156\n",
      "current loss = 2.2990872859954834\n",
      "current loss = 2.3036181926727295\n",
      "current loss = 2.3012051582336426\n",
      "current loss = 2.299107789993286\n",
      "current loss = 2.304032325744629\n",
      "current loss = 2.302309513092041\n",
      "current loss = 2.3059208393096924\n",
      "current loss = 2.300032138824463\n",
      "current loss = 2.301020622253418\n",
      "current loss = 2.3056299686431885\n",
      "current loss = 2.307912588119507\n",
      "current loss = 2.299537181854248\n",
      "current loss = 2.306818962097168\n",
      "current loss = 2.2993178367614746\n",
      "current loss = 2.3053138256073\n",
      "current loss = 2.3034589290618896\n",
      "current loss = 2.3054637908935547\n",
      "current loss = 2.2996485233306885\n",
      "current loss = 2.3060696125030518\n",
      "current loss = 2.3051645755767822\n",
      "current loss = 2.3040108680725098\n",
      "current loss = 2.3008928298950195\n",
      "current loss = 2.3031418323516846\n",
      "current loss = 2.3088412284851074\n",
      "current loss = 2.3001670837402344\n",
      "current loss = 2.2996764183044434\n",
      "current loss = 2.3069536685943604\n",
      "current loss = 2.3034861087799072\n",
      "current loss = 2.3044183254241943\n",
      "current loss = 2.302677869796753\n",
      "current loss = 2.3028604984283447\n",
      "current loss = 2.3061165809631348\n",
      "current loss = 2.309624195098877\n",
      "current loss = 2.2988739013671875\n",
      "current loss = 2.2986741065979004\n",
      "current loss = 2.303375244140625\n",
      "current loss = 2.3034870624542236\n",
      "current loss = 2.2995851039886475\n",
      "current loss = 2.3003385066986084\n",
      "current loss = 2.3038766384124756\n",
      "current loss = 2.3026931285858154\n",
      "current loss = 2.302053928375244\n",
      "current loss = 2.2993662357330322\n",
      "current loss = 2.3068628311157227\n",
      "current loss = 2.3003499507904053\n",
      "current loss = 2.302276134490967\n",
      "current loss = 2.299015998840332\n",
      "current loss = 2.301637887954712\n",
      "current loss = 2.3049886226654053\n",
      "current loss = 2.3059003353118896\n",
      "current loss = 2.3003480434417725\n",
      "current loss = 2.2993273735046387\n",
      "current loss = 2.2983317375183105\n",
      "current loss = 2.3038270473480225\n",
      "current loss = 2.3008577823638916\n",
      "current loss = 2.3039727210998535\n",
      "current loss = 2.3021011352539062\n",
      "current loss = 2.304140090942383\n",
      "current loss = 2.3019015789031982\n",
      "current loss = 2.3015482425689697\n",
      "current loss = 2.305121421813965\n",
      "current loss = 2.3020412921905518\n",
      "current loss = 2.3014495372772217\n",
      "current loss = 2.304302453994751\n",
      "current loss = 2.3001015186309814\n",
      "current loss = 2.302553653717041\n",
      "current loss = 2.306405782699585\n",
      "current loss = 2.3026726245880127\n",
      "current loss = 2.298506259918213\n",
      "current loss = 2.3017349243164062\n",
      "current loss = 2.306811809539795\n",
      "current loss = 2.304739236831665\n",
      "current loss = 2.303504467010498\n",
      "current loss = 2.3030025959014893\n",
      "current loss = 2.3017797470092773\n",
      "current loss = 2.2997148036956787\n",
      "current loss = 2.304577112197876\n",
      "current loss = 2.304518461227417\n",
      "current loss = 2.3048431873321533\n",
      "current loss = 2.301285743713379\n",
      "current loss = 2.300685405731201\n",
      "current loss = 2.301844596862793\n",
      "current loss = 2.302753210067749\n",
      "current loss = 2.301387071609497\n",
      "current loss = 2.302171230316162\n",
      "current loss = 2.3051908016204834\n",
      "current loss = 2.3038833141326904\n",
      "current loss = 2.3033578395843506\n",
      "current loss = 2.2956438064575195\n",
      "current loss = 2.3019044399261475\n",
      "current loss = 2.3050613403320312\n",
      "current loss = 2.3006880283355713\n",
      "current loss = 2.292304039001465\n",
      "current loss = 2.300403118133545\n",
      "current loss = 2.302664279937744\n",
      "current loss = 2.300954818725586\n",
      "current loss = 2.2971692085266113\n",
      "current loss = 2.3061656951904297\n",
      "current loss = 2.3017616271972656\n",
      "current loss = 2.304429531097412\n",
      "current loss = 2.300701379776001\n",
      "current loss = 2.2988319396972656\n",
      "current loss = 2.3034021854400635\n",
      "current loss = 2.2986948490142822\n",
      "current loss = 2.301034450531006\n",
      "current loss = 2.305833101272583\n",
      "current loss = 2.301727056503296\n",
      "current loss = 2.29966139793396\n",
      "current loss = 2.2954161167144775\n",
      "current loss = 2.305023431777954\n",
      "current loss = 2.305551767349243\n",
      "current loss = 2.296823263168335\n",
      "current loss = 2.306032657623291\n",
      "current loss = 2.300122022628784\n",
      "current loss = 2.2996277809143066\n",
      "current loss = 2.29980731010437\n",
      "current loss = 2.2919445037841797\n",
      "current loss = 2.301356792449951\n",
      "current loss = 2.309753179550171\n",
      "current loss = 2.299923896789551\n",
      "current loss = 2.303537607192993\n",
      "current loss = 2.300063133239746\n",
      "current loss = 2.3055567741394043\n",
      "current loss = 2.30788516998291\n",
      "current loss = 2.309392213821411\n",
      "current loss = 2.3066422939300537\n",
      "current loss = 2.311558723449707\n",
      "current loss = 2.3088948726654053\n",
      "current loss = 2.305422782897949\n",
      "current loss = 2.3043954372406006\n",
      "current loss = 2.3013792037963867\n",
      "current loss = 2.298011064529419\n",
      "current loss = 2.3045711517333984\n",
      "current loss = 2.3125267028808594\n",
      "current loss = 2.3085439205169678\n",
      "current loss = 2.2973732948303223\n",
      "current loss = 2.3022754192352295\n",
      "current loss = 2.3064064979553223\n",
      "current loss = 2.3043019771575928\n",
      "current loss = 2.2971668243408203\n",
      "current loss = 2.30399227142334\n",
      "current loss = 2.3030929565429688\n",
      "current loss = 2.305448055267334\n",
      "current loss = 2.3032379150390625\n",
      "current loss = 2.304481267929077\n",
      "current loss = 2.302216053009033\n",
      "current loss = 2.2932074069976807\n",
      "current loss = 2.304582118988037\n",
      "current loss = 2.3059580326080322\n",
      "current loss = 2.3101372718811035\n",
      "current loss = 2.307147741317749\n",
      "current loss = 2.3047611713409424\n",
      "current loss = 2.3037965297698975\n",
      "current loss = 2.3009815216064453\n",
      "current loss = 2.3009445667266846\n",
      "current loss = 2.3009705543518066\n",
      "current loss = 2.3072850704193115\n",
      "current loss = 2.3053510189056396\n",
      "current loss = 2.30718731880188\n",
      "current loss = 2.3045711517333984\n",
      "current loss = 2.2988359928131104\n",
      "current loss = 2.304957628250122\n",
      "current loss = 2.30078125\n",
      "current loss = 2.302119255065918\n",
      "current loss = 2.300525188446045\n",
      "current loss = 2.301024913787842\n",
      "current loss = 2.295020818710327\n",
      "current loss = 2.2972466945648193\n",
      "current loss = 2.300234079360962\n",
      "current loss = 2.3064911365509033\n",
      "current loss = 2.3037943840026855\n",
      "current loss = 2.3049356937408447\n",
      "current loss = 2.3038508892059326\n",
      "current loss = 2.306257724761963\n",
      "current loss = 2.3038153648376465\n",
      "current loss = 2.307410955429077\n",
      "current loss = 2.305431842803955\n",
      "current loss = 2.3030800819396973\n",
      "current loss = 2.306135416030884\n",
      "current loss = 2.303499460220337\n",
      "current loss = 2.3035473823547363\n",
      "current loss = 2.2979066371917725\n",
      "current loss = 2.304218292236328\n",
      "current loss = 2.304439067840576\n",
      "current loss = 2.304117441177368\n",
      "current loss = 2.3013622760772705\n",
      "current loss = 2.3019001483917236\n",
      "current loss = 2.305086374282837\n",
      "current loss = 2.3037171363830566\n",
      "current loss = 2.302783250808716\n",
      "current loss = 2.304370403289795\n",
      "current loss = 2.305889844894409\n",
      "current loss = 2.3045077323913574\n",
      "current loss = 2.303823471069336\n",
      "current loss = 2.3011109828948975\n",
      "current loss = 2.3065550327301025\n",
      "current loss = 2.3034555912017822\n",
      "current loss = 2.2993762493133545\n",
      "current loss = 2.3002328872680664\n",
      "current loss = 2.3047022819519043\n",
      "current loss = 2.3015778064727783\n",
      "current loss = 2.3060922622680664\n",
      "current loss = 2.3055388927459717\n",
      "current loss = 2.3009321689605713\n",
      "current loss = 2.3032774925231934\n",
      "current loss = 2.302126407623291\n",
      "current loss = 2.3031084537506104\n",
      "current loss = 2.302842140197754\n",
      "current loss = 2.3001723289489746\n",
      "current loss = 2.3041932582855225\n",
      "current loss = 2.3018105030059814\n",
      "current loss = 2.3013625144958496\n",
      "current loss = 2.3031907081604004\n",
      "current loss = 2.299656391143799\n",
      "current loss = 2.3038246631622314\n",
      "current loss = 2.303372621536255\n",
      "current loss = 2.3056821823120117\n",
      "current loss = 2.3098108768463135\n",
      "current loss = 2.2980170249938965\n",
      "current loss = 2.3055787086486816\n",
      "current loss = 2.305635452270508\n",
      "current loss = 2.3052518367767334\n",
      "current loss = 2.29933500289917\n",
      "current loss = 2.2984118461608887\n",
      "current loss = 2.3038082122802734\n",
      "current loss = 2.303730010986328\n",
      "current loss = 2.302213430404663\n",
      "current loss = 2.3033201694488525\n",
      "current loss = 2.3048715591430664\n",
      "current loss = 2.3033297061920166\n",
      "current loss = 2.303948163986206\n",
      "current loss = 2.2989389896392822\n",
      "current loss = 2.3025412559509277\n",
      "current loss = 2.305269241333008\n",
      "current loss = 2.3009731769561768\n",
      "current loss = 2.300234317779541\n",
      "current loss = 2.303241729736328\n",
      "current loss = 2.30395245552063\n",
      "current loss = 2.298691511154175\n",
      "current loss = 2.3051388263702393\n",
      "current loss = 2.303673267364502\n",
      "current loss = 2.3026461601257324\n",
      "current loss = 2.3048338890075684\n",
      "current loss = 2.3022422790527344\n",
      "current loss = 2.3029091358184814\n",
      "current loss = 2.2981643676757812\n",
      "current loss = 2.301095962524414\n",
      "current loss = 2.298727035522461\n",
      "current loss = 2.3036530017852783\n",
      "current loss = 2.29910945892334\n",
      "current loss = 2.2988247871398926\n",
      "current loss = 2.3054287433624268\n",
      "current loss = 2.3015451431274414\n",
      "current loss = 2.3038275241851807\n",
      "current loss = 2.2997779846191406\n",
      "current loss = 2.3038153648376465\n",
      "current loss = 2.303842782974243\n",
      "current loss = 2.299095392227173\n",
      "current loss = 2.302762508392334\n",
      "current loss = 2.3031680583953857\n",
      "current loss = 2.3021233081817627\n",
      "current loss = 2.3022990226745605\n",
      "current loss = 2.304863214492798\n",
      "current loss = 2.301114320755005\n",
      "current loss = 2.3082633018493652\n",
      "current loss = 2.301697015762329\n",
      "current loss = 2.305015802383423\n",
      "current loss = 2.299858570098877\n",
      "current loss = 2.298710584640503\n",
      "current loss = 2.3006489276885986\n",
      "current loss = 2.3077056407928467\n",
      "current loss = 2.298567295074463\n",
      "current loss = 2.3033344745635986\n",
      "current loss = 2.2978076934814453\n",
      "current loss = 2.3002874851226807\n",
      "current loss = 2.3035976886749268\n",
      "current loss = 2.301504373550415\n",
      "current loss = 2.304260015487671\n",
      "current loss = 2.3085885047912598\n",
      "current loss = 2.3011372089385986\n",
      "current loss = 2.302053451538086\n",
      "current loss = 2.3069257736206055\n",
      "current loss = 2.303523540496826\n",
      "current loss = 2.307729959487915\n",
      "current loss = 2.3008124828338623\n",
      "current loss = 2.303056240081787\n",
      "current loss = 2.3015029430389404\n",
      "current loss = 2.3031630516052246\n",
      "current loss = 2.2998359203338623\n",
      "current loss = 2.3020589351654053\n",
      "current loss = 2.3000752925872803\n",
      "current loss = 2.3011085987091064\n",
      "current loss = 2.305798292160034\n",
      "current loss = 2.29348087310791\n",
      "current loss = 2.3035874366760254\n",
      "current loss = 2.3012232780456543\n",
      "current loss = 2.3033721446990967\n",
      "current loss = 2.2975759506225586\n",
      "current loss = 2.3053033351898193\n",
      "current loss = 2.300628185272217\n",
      "current loss = 2.302929401397705\n",
      "current loss = 2.3043696880340576\n",
      "current loss = 2.301731586456299\n",
      "current loss = 2.29974365234375\n",
      "current loss = 2.307158946990967\n",
      "current loss = 2.2967963218688965\n",
      "current loss = 2.304872751235962\n",
      "current loss = 2.304992437362671\n",
      "current loss = 2.302187919616699\n",
      "current loss = 2.302924871444702\n",
      "current loss = 2.303057909011841\n",
      "current loss = 2.300222635269165\n",
      "current loss = 2.29770565032959\n",
      "current loss = 2.303086519241333\n",
      "current loss = 2.2994463443756104\n",
      "current loss = 2.306023597717285\n",
      "current loss = 2.299558162689209\n",
      "current loss = 2.305996894836426\n",
      "current loss = 2.3084964752197266\n",
      "current loss = 2.302492380142212\n",
      "current loss = 2.304090976715088\n",
      "current loss = 2.3022215366363525\n",
      "current loss = 2.3028066158294678\n",
      "current loss = 2.303271770477295\n",
      "current loss = 2.2974462509155273\n",
      "current loss = 2.3044004440307617\n",
      "current loss = 2.3041398525238037\n",
      "current loss = 2.30454158782959\n",
      "current loss = 2.3019211292266846\n",
      "current loss = 2.2988295555114746\n",
      "current loss = 2.306434154510498\n",
      "current loss = 2.2980968952178955\n",
      "current loss = 2.3030169010162354\n",
      "current loss = 2.2999157905578613\n",
      "current loss = 2.3049049377441406\n",
      "current loss = 2.301527261734009\n",
      "current loss = 2.2982757091522217\n",
      "current loss = 2.3081674575805664\n",
      "current loss = 2.308145761489868\n",
      "current loss = 2.3014016151428223\n",
      "current loss = 2.2987375259399414\n",
      "current loss = 2.3020377159118652\n",
      "current loss = 2.3009748458862305\n",
      "current loss = 2.303915023803711\n",
      "current loss = 2.29938006401062\n",
      "current loss = 2.301363945007324\n",
      "current loss = 2.305575370788574\n",
      "current loss = 2.3064937591552734\n",
      "current loss = 2.301692008972168\n",
      "current loss = 2.304311752319336\n",
      "current loss = 2.3035027980804443\n",
      "current loss = 2.302849531173706\n",
      "current loss = 2.3047738075256348\n",
      "current loss = 2.302293300628662\n",
      "current loss = 2.304887294769287\n",
      "current loss = 2.3001160621643066\n",
      "current loss = 2.3008458614349365\n",
      "current loss = 2.300816774368286\n",
      "current loss = 2.300046443939209\n",
      "current loss = 2.306608200073242\n",
      "current loss = 2.304476261138916\n",
      "current loss = 2.3049204349517822\n",
      "current loss = 2.303663730621338\n",
      "current loss = 2.2960331439971924\n",
      "current loss = 2.3033628463745117\n",
      "current loss = 2.3063247203826904\n",
      "current loss = 2.3048648834228516\n",
      "current loss = 2.299553871154785\n",
      "current loss = 2.302964210510254\n",
      "current loss = 2.3013627529144287\n",
      "current loss = 2.3053650856018066\n",
      "current loss = 2.302844524383545\n",
      "current loss = 2.299421787261963\n",
      "current loss = 2.3044261932373047\n",
      "current loss = 2.300628185272217\n",
      "current loss = 2.2999932765960693\n",
      "current loss = 2.3007431030273438\n",
      "current loss = 2.3022689819335938\n",
      "current loss = 2.303417444229126\n",
      "current loss = 2.308469295501709\n",
      "current loss = 2.3048179149627686\n",
      "current loss = 2.30631160736084\n",
      "current loss = 2.3048133850097656\n",
      "current loss = 2.298781156539917\n",
      "current loss = 2.3024790287017822\n",
      "current loss = 2.302602529525757\n",
      "current loss = 2.300905227661133\n",
      "current loss = 2.3022751808166504\n",
      "current loss = 2.3030598163604736\n",
      "current loss = 2.3021745681762695\n",
      "current loss = 2.3016605377197266\n",
      "current loss = 2.3056888580322266\n",
      "current loss = 2.303562641143799\n",
      "current loss = 2.3050739765167236\n",
      "current loss = 2.2999019622802734\n",
      "current loss = 2.3044345378875732\n",
      "current loss = 2.306025981903076\n",
      "current loss = 2.3034780025482178\n",
      "current loss = 2.306328773498535\n",
      "current loss = 2.3013675212860107\n",
      "current loss = 2.299778699874878\n",
      "current loss = 2.302302360534668\n",
      "current loss = 2.30002498626709\n",
      "current loss = 2.298769950866699\n",
      "current loss = 2.302659034729004\n",
      "current loss = 2.3028147220611572\n",
      "current loss = 2.2993104457855225\n",
      "current loss = 2.3007867336273193\n",
      "current loss = 2.303014039993286\n",
      "current loss = 2.300657272338867\n",
      "current loss = 2.305100917816162\n",
      "current loss = 2.2972307205200195\n",
      "current loss = 2.3018722534179688\n",
      "current loss = 2.302192211151123\n",
      "current loss = 2.3005874156951904\n",
      "current loss = 2.3041296005249023\n",
      "current loss = 2.305929183959961\n",
      "current loss = 2.3008182048797607\n",
      "current loss = 2.3002138137817383\n",
      "current loss = 2.3110861778259277\n",
      "current loss = 2.2981550693511963\n",
      "current loss = 2.3035967350006104\n",
      "current loss = 2.304335117340088\n",
      "current loss = 2.3010222911834717\n",
      "current loss = 2.304511547088623\n",
      "current loss = 2.305152177810669\n",
      "current loss = 2.304849863052368\n",
      "current loss = 2.303616762161255\n",
      "current loss = 2.305304527282715\n",
      "current loss = 2.3010029792785645\n",
      "current loss = 2.3018555641174316\n",
      "current loss = 2.2984731197357178\n",
      "current loss = 2.30239200592041\n",
      "current loss = 2.3010056018829346\n",
      "current loss = 2.3045694828033447\n",
      "current loss = 2.3030900955200195\n",
      "current loss = 2.30590558052063\n",
      "current loss = 2.3017420768737793\n",
      "current loss = 2.299999475479126\n",
      "current loss = 2.3027703762054443\n",
      "current loss = 2.3033249378204346\n",
      "current loss = 2.3084046840667725\n",
      "current loss = 2.3004651069641113\n",
      "current loss = 2.3002376556396484\n",
      "current loss = 2.299467086791992\n",
      "current loss = 2.3047027587890625\n",
      "current loss = 2.3040473461151123\n",
      "current loss = 2.3044774532318115\n",
      "current loss = 2.300955295562744\n",
      "current loss = 2.3004167079925537\n",
      "current loss = 2.30414080619812\n",
      "current loss = 2.308434247970581\n",
      "current loss = 2.3049259185791016\n",
      "current loss = 2.3064582347869873\n",
      "current loss = 2.3010871410369873\n",
      "current loss = 2.3034324645996094\n",
      "current loss = 2.302325487136841\n",
      "current loss = 2.300565719604492\n",
      "current loss = 2.3043735027313232\n",
      "current loss = 2.301823854446411\n",
      "current loss = 2.3023250102996826\n",
      "current loss = 2.2992465496063232\n",
      "current loss = 2.304615020751953\n",
      "current loss = 2.2995829582214355\n",
      "current loss = 2.304534912109375\n",
      "current loss = 2.3002729415893555\n",
      "current loss = 2.300294876098633\n",
      "current loss = 2.300306797027588\n",
      "current loss = 2.3048248291015625\n",
      "current loss = 2.3027141094207764\n",
      "current loss = 2.3010575771331787\n",
      "current loss = 2.2991552352905273\n",
      "current loss = 2.304567575454712\n",
      "current loss = 2.304333209991455\n",
      "current loss = 2.302485704421997\n",
      "current loss = 2.302363872528076\n",
      "current loss = 2.304076910018921\n",
      "current loss = 2.302091360092163\n",
      "current loss = 2.3030662536621094\n",
      "current loss = 2.301405191421509\n",
      "current loss = 2.3024985790252686\n",
      "current loss = 2.298957347869873\n",
      "current loss = 2.303020477294922\n",
      "current loss = 2.304772138595581\n",
      "current loss = 2.3004424571990967\n",
      "current loss = 2.3025333881378174\n",
      "current loss = 2.3035902976989746\n",
      "current loss = 2.30051851272583\n",
      "current loss = 2.303617238998413\n",
      "current loss = 2.2994885444641113\n",
      "current loss = 2.3028645515441895\n",
      "current loss = 2.3027894496917725\n",
      "current loss = 2.306307554244995\n",
      "current loss = 2.304797410964966\n",
      "current loss = 2.305126428604126\n",
      "current loss = 2.3002710342407227\n",
      "current loss = 2.303842067718506\n",
      "current loss = 2.3017005920410156\n",
      "current loss = 2.302501678466797\n",
      "current loss = 2.30509090423584\n",
      "current loss = 2.2987983226776123\n",
      "current loss = 2.3008124828338623\n",
      "current loss = 2.308750629425049\n",
      "current loss = 2.3020431995391846\n",
      "current loss = 2.3013951778411865\n",
      "current loss = 2.3026349544525146\n",
      "current loss = 2.3010218143463135\n",
      "current loss = 2.302950620651245\n",
      "current loss = 2.298231840133667\n",
      "current loss = 2.302766799926758\n",
      "current loss = 2.302170753479004\n",
      "current loss = 2.3002066612243652\n",
      "current loss = 2.2993156909942627\n",
      "current loss = 2.305294990539551\n",
      "current loss = 2.300320863723755\n",
      "current loss = 2.301936149597168\n",
      "current loss = 2.302340030670166\n",
      "current loss = 2.3008618354797363\n",
      "current loss = 2.3030359745025635\n",
      "current loss = 2.30267596244812\n",
      "current loss = 2.299314260482788\n",
      "current loss = 2.3025500774383545\n",
      "current loss = 2.299011707305908\n",
      "current loss = 2.3060450553894043\n",
      "current loss = 2.3038876056671143\n",
      "current loss = 2.308147430419922\n",
      "current loss = 2.303043842315674\n",
      "current loss = 2.3020005226135254\n",
      "current loss = 2.30058217048645\n",
      "current loss = 2.305244207382202\n",
      "current loss = 2.2998852729797363\n",
      "current loss = 2.3012197017669678\n",
      "current loss = 2.3046724796295166\n",
      "current loss = 2.2994422912597656\n",
      "current loss = 2.3018901348114014\n",
      "current loss = 2.299407720565796\n",
      "current loss = 2.301093578338623\n",
      "current loss = 2.3030362129211426\n",
      "current loss = 2.30291485786438\n",
      "current loss = 2.2975211143493652\n",
      "current loss = 2.306781768798828\n",
      "current loss = 2.2978382110595703\n",
      "current loss = 2.3056814670562744\n",
      "current loss = 2.302863121032715\n",
      "current loss = 2.300421953201294\n",
      "current loss = 2.3014819622039795\n",
      "current loss = 2.3060996532440186\n",
      "current loss = 2.300110101699829\n",
      "current loss = 2.3027713298797607\n",
      "current loss = 2.3035664558410645\n",
      "current loss = 2.303100109100342\n",
      "current loss = 2.302086353302002\n",
      "current loss = 2.2992072105407715\n",
      "current loss = 2.3027775287628174\n",
      "current loss = 2.3043620586395264\n",
      "current loss = 2.305474281311035\n",
      "current loss = 2.301939010620117\n",
      "current loss = 2.3004117012023926\n",
      "current loss = 2.304382562637329\n",
      "current loss = 2.303128480911255\n",
      "current loss = 2.2988271713256836\n",
      "current loss = 2.300745964050293\n",
      "current loss = 2.3061513900756836\n",
      "current loss = 2.2976386547088623\n",
      "current loss = 2.3093602657318115\n",
      "current loss = 2.300673246383667\n",
      "current loss = 2.304950475692749\n",
      "current loss = 2.3022422790527344\n",
      "current loss = 2.303049325942993\n",
      "current loss = 2.2999215126037598\n",
      "current loss = 2.3057749271392822\n",
      "current loss = 2.3045270442962646\n",
      "current loss = 2.3002073764801025\n",
      "current loss = 2.299647331237793\n",
      "current loss = 2.301008939743042\n",
      "current loss = 2.298785924911499\n",
      "current loss = 2.3023509979248047\n",
      "current loss = 2.3021180629730225\n",
      "current loss = 2.3014423847198486\n",
      "current loss = 2.304489850997925\n",
      "current loss = 2.302366256713867\n",
      "current loss = 2.302713394165039\n",
      "current loss = 2.2981929779052734\n",
      "current loss = 2.3060927391052246\n",
      "current loss = 2.300974130630493\n",
      "current loss = 2.301938772201538\n",
      "current loss = 2.305283784866333\n",
      "current loss = 2.305030107498169\n",
      "current loss = 2.3017501831054688\n",
      "current loss = 2.3058230876922607\n",
      "current loss = 2.304612159729004\n",
      "current loss = 2.306434392929077\n",
      "current loss = 2.3011531829833984\n",
      "current loss = 2.2985036373138428\n",
      "current loss = 2.3024234771728516\n",
      "current loss = 2.3047983646392822\n",
      "current loss = 2.2999563217163086\n",
      "current loss = 2.303846597671509\n",
      "current loss = 2.304258108139038\n",
      "current loss = 2.3049156665802\n",
      "current loss = 2.3029842376708984\n",
      "current loss = 2.2995662689208984\n",
      "current loss = 2.304084300994873\n",
      "current loss = 2.295405387878418\n",
      "current loss = 2.3027842044830322\n",
      "current loss = 2.306011199951172\n",
      "current loss = 2.3025619983673096\n",
      "current loss = 2.30578351020813\n",
      "current loss = 2.299677848815918\n",
      "current loss = 2.3040175437927246\n",
      "current loss = 2.2998056411743164\n",
      "current loss = 2.3061375617980957\n",
      "current loss = 2.299114942550659\n",
      "current loss = 2.3029468059539795\n",
      "current loss = 2.302278995513916\n",
      "current loss = 2.2972707748413086\n",
      "current loss = 2.302060842514038\n",
      "current loss = 2.3008322715759277\n",
      "current loss = 2.301663875579834\n",
      "current loss = 2.301882028579712\n",
      "current loss = 2.306988000869751\n",
      "current loss = 2.3022000789642334\n",
      "current loss = 2.2966976165771484\n",
      "current loss = 2.305424928665161\n",
      "current loss = 2.2979941368103027\n",
      "current loss = 2.301981210708618\n",
      "current loss = 2.3054628372192383\n",
      "current loss = 2.3038012981414795\n",
      "current loss = 2.2959654331207275\n",
      "current loss = 2.2976109981536865\n",
      "current loss = 2.298445224761963\n",
      "current loss = 2.3058977127075195\n",
      "current loss = 2.302111864089966\n",
      "current loss = 2.300497055053711\n",
      "current loss = 2.301135778427124\n",
      "current loss = 2.3017165660858154\n",
      "current loss = 2.303332805633545\n",
      "current loss = 2.298513650894165\n",
      "current loss = 2.305267095565796\n",
      "current loss = 2.2986998558044434\n",
      "current loss = 2.2993249893188477\n",
      "current loss = 2.3050625324249268\n",
      "current loss = 2.30647611618042\n",
      "current loss = 2.299532413482666\n",
      "current loss = 2.304370403289795\n",
      "current loss = 2.302677869796753\n",
      "current loss = 2.2971384525299072\n",
      "current loss = 2.3012337684631348\n",
      "current loss = 2.3042452335357666\n",
      "current loss = 2.3026344776153564\n",
      "current loss = 2.3009445667266846\n",
      "current loss = 2.30257511138916\n",
      "current loss = 2.3017921447753906\n",
      "current loss = 2.3029825687408447\n",
      "current loss = 2.3033878803253174\n",
      "current loss = 2.3054301738739014\n",
      "current loss = 2.3032402992248535\n",
      "current loss = 2.3002805709838867\n",
      "current loss = 2.304875612258911\n",
      "current loss = 2.302121162414551\n",
      "current loss = 2.3012380599975586\n",
      "current loss = 2.3039398193359375\n",
      "current loss = 2.2945070266723633\n",
      "current loss = 2.298529863357544\n",
      "current loss = 2.3077752590179443\n",
      "current loss = 2.3012607097625732\n",
      "current loss = 2.3023288249969482\n",
      "current loss = 2.2998032569885254\n",
      "current loss = 2.299595594406128\n",
      "current loss = 2.3005166053771973\n",
      "current loss = 2.2977404594421387\n",
      "current loss = 2.3021535873413086\n",
      "current loss = 2.301858901977539\n",
      "current loss = 2.3023717403411865\n",
      "current loss = 2.299717664718628\n",
      "current loss = 2.300994634628296\n",
      "current loss = 2.301931381225586\n",
      "current loss = 2.299847364425659\n",
      "current loss = 2.300082206726074\n",
      "current loss = 2.2985808849334717\n",
      "current loss = 2.309013605117798\n",
      "current loss = 2.307572603225708\n",
      "current loss = 2.304353952407837\n",
      "current loss = 2.30256724357605\n",
      "current loss = 2.3089747428894043\n",
      "current loss = 2.3069748878479004\n",
      "current loss = 2.300480842590332\n",
      "current loss = 2.3028457164764404\n",
      "current loss = 2.301652669906616\n",
      "current loss = 2.3007264137268066\n",
      "current loss = 2.2965617179870605\n",
      "current loss = 2.303335428237915\n",
      "current loss = 2.299246072769165\n",
      "current loss = 2.303025722503662\n",
      "current loss = 2.2973570823669434\n",
      "current loss = 2.2990469932556152\n",
      "current loss = 2.304713249206543\n",
      "current loss = 2.3026249408721924\n",
      "current loss = 2.3006136417388916\n",
      "current loss = 2.3068909645080566\n",
      "current loss = 2.30020809173584\n",
      "current loss = 2.3017759323120117\n",
      "current loss = 2.3080079555511475\n",
      "current loss = 2.2927331924438477\n",
      "current loss = 2.303807497024536\n",
      "current loss = 2.304157018661499\n",
      "current loss = 2.3019750118255615\n",
      "current loss = 2.30586576461792\n",
      "current loss = 2.3062326908111572\n",
      "current loss = 2.2977867126464844\n",
      "current loss = 2.3061418533325195\n",
      "current loss = 2.303893566131592\n",
      "current loss = 2.3065524101257324\n",
      "current loss = 2.3033485412597656\n",
      "current loss = 2.2971553802490234\n",
      "current loss = 2.297985792160034\n",
      "current loss = 2.2973880767822266\n",
      "current loss = 2.2995219230651855\n",
      "current loss = 2.311452627182007\n",
      "current loss = 2.307025909423828\n",
      "current loss = 2.3013644218444824\n",
      "current loss = 2.313400983810425\n",
      "current loss = 2.2998173236846924\n",
      "current loss = 2.303225517272949\n",
      "current loss = 2.298790216445923\n",
      "current loss = 2.297006368637085\n",
      "current loss = 2.3057262897491455\n",
      "current loss = 2.3012707233428955\n",
      "current loss = 2.296926498413086\n",
      "current loss = 2.3015198707580566\n",
      "current loss = 2.303666114807129\n",
      "current loss = 2.306089162826538\n",
      "current loss = 2.2990472316741943\n",
      "current loss = 2.309455394744873\n",
      "current loss = 2.3055872917175293\n",
      "current loss = 2.301105499267578\n",
      "current loss = 2.2991764545440674\n",
      "current loss = 2.2988834381103516\n",
      "current loss = 2.3052563667297363\n",
      "current loss = 2.299349308013916\n",
      "current loss = 2.3040788173675537\n",
      "current loss = 2.3025949001312256\n",
      "current loss = 2.301557779312134\n",
      "current loss = 2.306885242462158\n",
      "current loss = 2.3066928386688232\n",
      "current loss = 2.299492120742798\n",
      "current loss = 2.301527738571167\n",
      "current loss = 2.299410104751587\n",
      "current loss = 2.3026134967803955\n",
      "current loss = 2.3018689155578613\n",
      "current loss = 2.29864764213562\n",
      "current loss = 2.3011631965637207\n",
      "current loss = 2.29547119140625\n",
      "current loss = 2.295039176940918\n",
      "current loss = 2.304431915283203\n",
      "current loss = 2.302964925765991\n",
      "current loss = 2.3051350116729736\n",
      "current loss = 2.304926633834839\n",
      "current loss = 2.298081874847412\n",
      "current loss = 2.3032872676849365\n",
      "current loss = 2.3010544776916504\n",
      "current loss = 2.304795742034912\n",
      "current loss = 2.3101303577423096\n",
      "current loss = 2.307436227798462\n",
      "current loss = 2.3033792972564697\n",
      "current loss = 2.3077926635742188\n",
      "current loss = 2.302896022796631\n",
      "current loss = 2.3018598556518555\n",
      "current loss = 2.3018457889556885\n",
      "current loss = 2.2954626083374023\n",
      "current loss = 2.2993404865264893\n",
      "current loss = 2.3066930770874023\n",
      "current loss = 2.2982466220855713\n",
      "current loss = 2.3061113357543945\n",
      "current loss = 2.2980775833129883\n",
      "current loss = 2.298304557800293\n",
      "current loss = 2.305112600326538\n",
      "current loss = 2.297037124633789\n",
      "current loss = 2.299431562423706\n",
      "current loss = 2.29921817779541\n",
      "current loss = 2.31087064743042\n",
      "current loss = 2.3026838302612305\n",
      "current loss = 2.3014023303985596\n",
      "current loss = 2.3015613555908203\n",
      "current loss = 2.302121639251709\n",
      "current loss = 2.306917190551758\n",
      "current loss = 2.300168037414551\n",
      "current loss = 2.2971150875091553\n",
      "current loss = 2.3086841106414795\n",
      "current loss = 2.2940943241119385\n",
      "current loss = 2.3101541996002197\n",
      "current loss = 2.302738666534424\n",
      "current loss = 2.303640842437744\n",
      "current loss = 2.3105661869049072\n",
      "current loss = 2.303593635559082\n",
      "current loss = 2.3025918006896973\n",
      "current loss = 2.3005261421203613\n",
      "current loss = 2.3027195930480957\n",
      "current loss = 2.307387113571167\n",
      "current loss = 2.3045554161071777\n",
      "current loss = 2.301699638366699\n",
      "current loss = 2.3030436038970947\n",
      "current loss = 2.3043673038482666\n",
      "current loss = 2.303248167037964\n",
      "current loss = 2.3113293647766113\n",
      "current loss = 2.2975637912750244\n",
      "current loss = 2.296755313873291\n",
      "current loss = 2.3074145317077637\n",
      "current loss = 2.297821521759033\n",
      "current loss = 2.2956178188323975\n",
      "current loss = 2.302345037460327\n",
      "current loss = 2.299511194229126\n",
      "current loss = 2.305608034133911\n",
      "current loss = 2.302649974822998\n",
      "current loss = 2.3034815788269043\n",
      "current loss = 2.304683208465576\n",
      "current loss = 2.304133176803589\n",
      "current loss = 2.3040871620178223\n",
      "current loss = 2.3039846420288086\n",
      "current loss = 2.299328327178955\n",
      "current loss = 2.3018245697021484\n",
      "current loss = 2.3015809059143066\n",
      "current loss = 2.308657169342041\n",
      "current loss = 2.3006222248077393\n",
      "current loss = 2.3036959171295166\n",
      "current loss = 2.2958333492279053\n",
      "current loss = 2.3013668060302734\n",
      "current loss = 2.308236837387085\n",
      "current loss = 2.3006415367126465\n",
      "current loss = 2.301704168319702\n",
      "current loss = 2.2980194091796875\n",
      "current loss = 2.303966999053955\n",
      "current loss = 2.30501127243042\n",
      "current loss = 2.3065807819366455\n",
      "current loss = 2.303596258163452\n",
      "current loss = 2.302201509475708\n",
      "current loss = 2.3118107318878174\n",
      "current loss = 2.3003506660461426\n",
      "current loss = 2.3007614612579346\n",
      "current loss = 2.301673650741577\n",
      "current loss = 2.3051087856292725\n",
      "current loss = 2.3030409812927246\n",
      "current loss = 2.3004488945007324\n",
      "current loss = 2.303385019302368\n",
      "current loss = 2.3018617630004883\n",
      "current loss = 2.3065643310546875\n",
      "current loss = 2.305377244949341\n",
      "current loss = 2.3027241230010986\n",
      "current loss = 2.30348539352417\n",
      "current loss = 2.3022255897521973\n",
      "current loss = 2.3000433444976807\n",
      "current loss = 2.300758123397827\n",
      "current loss = 2.3093574047088623\n",
      "current loss = 2.3037455081939697\n",
      "current loss = 2.2997148036956787\n",
      "current loss = 2.2991232872009277\n",
      "current loss = 2.3035693168640137\n",
      "current loss = 2.3018176555633545\n",
      "current loss = 2.2991445064544678\n",
      "current loss = 2.2984423637390137\n",
      "current loss = 2.30415415763855\n",
      "current loss = 2.2996602058410645\n",
      "current loss = 2.3041434288024902\n",
      "current loss = 2.301038980484009\n",
      "current loss = 2.304219961166382\n",
      "current loss = 2.3051681518554688\n",
      "current loss = 2.308110237121582\n",
      "current loss = 2.30255126953125\n",
      "current loss = 2.3059146404266357\n",
      "current loss = 2.304119110107422\n",
      "current loss = 2.306051731109619\n",
      "current loss = 2.303598642349243\n",
      "current loss = 2.3043315410614014\n",
      "current loss = 2.3037593364715576\n",
      "current loss = 2.303969383239746\n",
      "current loss = 2.295398235321045\n",
      "current loss = 2.3007924556732178\n",
      "current loss = 2.301220655441284\n",
      "current loss = 2.2999753952026367\n",
      "current loss = 2.302489757537842\n",
      "current loss = 2.3032357692718506\n",
      "current loss = 2.300589084625244\n",
      "current loss = 2.303255081176758\n",
      "current loss = 2.302156448364258\n",
      "current loss = 2.302804946899414\n",
      "current loss = 2.300089120864868\n",
      "current loss = 2.3030192852020264\n",
      "current loss = 2.304394245147705\n",
      "current loss = 2.3014943599700928\n",
      "current loss = 2.30188250541687\n",
      "current loss = 2.3016271591186523\n",
      "current loss = 2.3016200065612793\n",
      "current loss = 2.303197145462036\n",
      "current loss = 2.3059606552124023\n",
      "current loss = 2.30233097076416\n",
      "current loss = 2.3023593425750732\n",
      "current loss = 2.308777332305908\n",
      "current loss = 2.306684970855713\n",
      "current loss = 2.3022890090942383\n",
      "current loss = 2.303987979888916\n",
      "current loss = 2.302858352661133\n",
      "current loss = 2.301274299621582\n",
      "current loss = 2.3010172843933105\n",
      "current loss = 2.302696466445923\n",
      "current loss = 2.300790786743164\n",
      "current loss = 2.306384563446045\n",
      "current loss = 2.303675651550293\n",
      "current loss = 2.303363800048828\n",
      "current loss = 2.300889492034912\n",
      "current loss = 2.299842596054077\n",
      "current loss = 2.3021554946899414\n",
      "current loss = 2.3056201934814453\n",
      "current loss = 2.299360752105713\n",
      "current loss = 2.3014893531799316\n",
      "current loss = 2.304443120956421\n",
      "current loss = 2.3020761013031006\n",
      "current loss = 2.298870325088501\n",
      "current loss = 2.3031768798828125\n",
      "current loss = 2.2991178035736084\n",
      "current loss = 2.3036439418792725\n",
      "current loss = 2.2966058254241943\n",
      "current loss = 2.301949977874756\n",
      "current loss = 2.2990283966064453\n",
      "current loss = 2.299802303314209\n",
      "current loss = 2.301969528198242\n",
      "current loss = 2.303164005279541\n",
      "current loss = 2.302896499633789\n",
      "current loss = 2.3018054962158203\n",
      "current loss = 2.304579496383667\n",
      "current loss = 2.303542375564575\n",
      "current loss = 2.298125743865967\n",
      "current loss = 2.3061740398406982\n",
      "current loss = 2.3010997772216797\n",
      "current loss = 2.300344228744507\n",
      "current loss = 2.3010060787200928\n",
      "current loss = 2.3067593574523926\n",
      "current loss = 2.30149507522583\n",
      "current loss = 2.3036553859710693\n",
      "current loss = 2.301358938217163\n",
      "current loss = 2.3033266067504883\n",
      "current loss = 2.303551435470581\n",
      "current loss = 2.307223320007324\n",
      "current loss = 2.304279088973999\n",
      "current loss = 2.3011624813079834\n",
      "current loss = 2.298020124435425\n",
      "current loss = 2.301823139190674\n",
      "current loss = 2.305682420730591\n",
      "current loss = 2.3014137744903564\n",
      "current loss = 2.295992374420166\n",
      "current loss = 2.303375482559204\n",
      "current loss = 2.3020076751708984\n",
      "current loss = 2.3056063652038574\n",
      "current loss = 2.300433874130249\n",
      "current loss = 2.299424648284912\n",
      "current loss = 2.3039193153381348\n",
      "current loss = 2.303312301635742\n",
      "current loss = 2.301831007003784\n",
      "current loss = 2.3038594722747803\n",
      "current loss = 2.3066091537475586\n",
      "current loss = 2.3035316467285156\n",
      "current loss = 2.3027191162109375\n",
      "current loss = 2.3074300289154053\n",
      "current loss = 2.2978198528289795\n",
      "current loss = 2.300100326538086\n",
      "current loss = 2.301038980484009\n",
      "current loss = 2.3046751022338867\n",
      "current loss = 2.3001697063446045\n",
      "current loss = 2.301246166229248\n",
      "current loss = 2.3045566082000732\n",
      "current loss = 2.304077625274658\n",
      "current loss = 2.3021013736724854\n",
      "current loss = 2.304730176925659\n",
      "current loss = 2.30111026763916\n",
      "current loss = 2.3049917221069336\n",
      "current loss = 2.29866886138916\n",
      "current loss = 2.302762746810913\n",
      "current loss = 2.3023574352264404\n",
      "current loss = 2.304490327835083\n",
      "current loss = 2.302212715148926\n",
      "current loss = 2.3042163848876953\n",
      "current loss = 2.3030459880828857\n",
      "current loss = 2.302251100540161\n",
      "current loss = 2.3006279468536377\n",
      "current loss = 2.3014285564422607\n",
      "current loss = 2.305779457092285\n",
      "current loss = 2.3007171154022217\n",
      "current loss = 2.3051633834838867\n",
      "current loss = 2.300184726715088\n",
      "current loss = 2.3047354221343994\n",
      "current loss = 2.3007867336273193\n",
      "current loss = 2.3021738529205322\n",
      "current loss = 2.297133207321167\n",
      "current loss = 2.304920196533203\n",
      "current loss = 2.297719955444336\n",
      "current loss = 2.3045616149902344\n",
      "current loss = 2.3027310371398926\n",
      "current loss = 2.3008060455322266\n",
      "current loss = 2.3031256198883057\n",
      "current loss = 2.3003311157226562\n",
      "current loss = 2.2973568439483643\n",
      "current loss = 2.302253246307373\n",
      "current loss = 2.3074588775634766\n",
      "current loss = 2.302600860595703\n",
      "current loss = 2.3041110038757324\n",
      "current loss = 2.307152271270752\n",
      "current loss = 2.300097703933716\n",
      "current loss = 2.304155111312866\n",
      "current loss = 2.303213119506836\n",
      "current loss = 2.3036088943481445\n",
      "current loss = 2.3083689212799072\n",
      "current loss = 2.302178382873535\n",
      "current loss = 2.302424907684326\n",
      "current loss = 2.2981364727020264\n",
      "current loss = 2.3017470836639404\n",
      "current loss = 2.2958080768585205\n",
      "current loss = 2.3033599853515625\n",
      "current loss = 2.2948548793792725\n",
      "current loss = 2.302797794342041\n",
      "current loss = 2.3074917793273926\n",
      "current loss = 2.2984955310821533\n",
      "current loss = 2.2996349334716797\n",
      "current loss = 2.30161714553833\n",
      "current loss = 2.304213523864746\n",
      "current loss = 2.300483226776123\n",
      "current loss = 2.300816535949707\n",
      "current loss = 2.2997355461120605\n",
      "current loss = 2.3049585819244385\n",
      "current loss = 2.2964015007019043\n",
      "current loss = 2.307722806930542\n",
      "current loss = 2.3012378215789795\n",
      "current loss = 2.299083709716797\n",
      "current loss = 2.303208827972412\n",
      "current loss = 2.3032777309417725\n",
      "current loss = 2.300053119659424\n",
      "current loss = 2.306525468826294\n",
      "current loss = 2.3006157875061035\n",
      "current loss = 2.3017780780792236\n",
      "current loss = 2.30297589302063\n",
      "current loss = 2.3011107444763184\n",
      "current loss = 2.3024184703826904\n",
      "current loss = 2.3054583072662354\n",
      "current loss = 2.302633047103882\n",
      "current loss = 2.30120849609375\n",
      "current loss = 2.300856351852417\n",
      "current loss = 2.2991347312927246\n",
      "current loss = 2.3025765419006348\n",
      "current loss = 2.3013806343078613\n",
      "current loss = 2.3013381958007812\n",
      "current loss = 2.301788330078125\n",
      "current loss = 2.30324649810791\n",
      "current loss = 2.3044958114624023\n",
      "current loss = 2.3043127059936523\n",
      "current loss = 2.2995972633361816\n",
      "current loss = 2.307267427444458\n",
      "current loss = 2.301504611968994\n",
      "current loss = 2.3072216510772705\n",
      "current loss = 2.3032376766204834\n",
      "current loss = 2.3064448833465576\n",
      "current loss = 2.3017144203186035\n",
      "current loss = 2.300869941711426\n",
      "current loss = 2.3062446117401123\n",
      "current loss = 2.305729866027832\n",
      "current loss = 2.307809352874756\n",
      "current loss = 2.300597906112671\n",
      "current loss = 2.30477237701416\n",
      "current loss = 2.3011982440948486\n",
      "current loss = 2.304285764694214\n",
      "current loss = 2.304489850997925\n",
      "current loss = 2.300103187561035\n",
      "current loss = 2.304485321044922\n",
      "current loss = 2.3018572330474854\n",
      "current loss = 2.301288366317749\n",
      "current loss = 2.2992866039276123\n",
      "current loss = 2.304157018661499\n",
      "current loss = 2.300025701522827\n",
      "current loss = 2.2986929416656494\n",
      "current loss = 2.303182363510132\n",
      "current loss = 2.305255651473999\n",
      "current loss = 2.3038249015808105\n",
      "current loss = 2.3014254570007324\n",
      "current loss = 2.3062314987182617\n",
      "current loss = 2.3011560440063477\n",
      "current loss = 2.303373336791992\n",
      "current loss = 2.303333282470703\n",
      "current loss = 2.3049609661102295\n",
      "current loss = 2.299757719039917\n",
      "current loss = 2.300596237182617\n",
      "current loss = 2.3048837184906006\n",
      "current loss = 2.3022658824920654\n",
      "current loss = 2.3043065071105957\n",
      "current loss = 2.2979445457458496\n",
      "current loss = 2.2995316982269287\n",
      "current loss = 2.301279306411743\n",
      "current loss = 2.298219919204712\n",
      "current loss = 2.3066279888153076\n",
      "current loss = 2.3004252910614014\n",
      "current loss = 2.306366205215454\n",
      "current loss = 2.299015760421753\n",
      "current loss = 2.301215410232544\n",
      "current loss = 2.303858995437622\n",
      "current loss = 2.2972748279571533\n",
      "current loss = 2.303624153137207\n",
      "current loss = 2.304506540298462\n",
      "current loss = 2.302607774734497\n",
      "current loss = 2.301762342453003\n",
      "current loss = 2.2987964153289795\n",
      "current loss = 2.303915500640869\n",
      "current loss = 2.299060344696045\n",
      "current loss = 2.299900770187378\n",
      "current loss = 2.3045172691345215\n",
      "current loss = 2.3020589351654053\n",
      "current loss = 2.301143169403076\n",
      "current loss = 2.298513412475586\n",
      "current loss = 2.302797317504883\n",
      "current loss = 2.299349308013916\n",
      "current loss = 2.298644781112671\n",
      "current loss = 2.3047709465026855\n",
      "current loss = 2.301205635070801\n",
      "current loss = 2.2975430488586426\n",
      "current loss = 2.3057568073272705\n",
      "current loss = 2.3048524856567383\n",
      "current loss = 2.300280809402466\n",
      "current loss = 2.3011109828948975\n",
      "current loss = 2.300266742706299\n",
      "current loss = 2.300819158554077\n",
      "current loss = 2.3020360469818115\n",
      "current loss = 2.3005263805389404\n",
      "current loss = 2.3036465644836426\n",
      "current loss = 2.301910638809204\n",
      "current loss = 2.3003501892089844\n",
      "current loss = 2.301034688949585\n",
      "current loss = 2.3028907775878906\n",
      "current loss = 2.300441026687622\n",
      "current loss = 2.2984073162078857\n",
      "current loss = 2.297710657119751\n",
      "current loss = 2.3013346195220947\n",
      "current loss = 2.3043243885040283\n",
      "current loss = 2.299832344055176\n",
      "current loss = 2.2994489669799805\n",
      "current loss = 2.307122230529785\n",
      "current loss = 2.3006153106689453\n",
      "current loss = 2.299549102783203\n",
      "current loss = 2.2990448474884033\n",
      "current loss = 2.3002681732177734\n",
      "current loss = 2.2978150844573975\n",
      "current loss = 2.3031201362609863\n",
      "current loss = 2.3030965328216553\n",
      "current loss = 2.3048744201660156\n",
      "current loss = 2.3047544956207275\n",
      "current loss = 2.2983720302581787\n",
      "current loss = 2.3043997287750244\n",
      "current loss = 2.299734592437744\n",
      "current loss = 2.30230975151062\n",
      "current loss = 2.304123640060425\n",
      "current loss = 2.3066234588623047\n",
      "current loss = 2.30299711227417\n",
      "current loss = 2.297577381134033\n",
      "current loss = 2.306250810623169\n",
      "current loss = 2.3008008003234863\n",
      "current loss = 2.292341470718384\n",
      "current loss = 2.3013763427734375\n",
      "current loss = 2.294696569442749\n",
      "current loss = 2.3048603534698486\n",
      "current loss = 2.2977468967437744\n",
      "current loss = 2.301628828048706\n",
      "current loss = 2.2983927726745605\n",
      "current loss = 2.299161911010742\n",
      "current loss = 2.300877809524536\n",
      "current loss = 2.2987024784088135\n",
      "current loss = 2.299124240875244\n",
      "current loss = 2.3034117221832275\n",
      "current loss = 2.3045079708099365\n",
      "current loss = 2.3111863136291504\n",
      "current loss = 2.3010997772216797\n",
      "current loss = 2.2984566688537598\n",
      "current loss = 2.3095409870147705\n",
      "current loss = 2.302494525909424\n",
      "current loss = 2.3001153469085693\n",
      "current loss = 2.304394483566284\n",
      "current loss = 2.302255630493164\n",
      "current loss = 2.3024446964263916\n",
      "current loss = 2.303598403930664\n",
      "current loss = 2.3043243885040283\n",
      "current loss = 2.300532341003418\n",
      "current loss = 2.3027162551879883\n",
      "current loss = 2.301107406616211\n",
      "current loss = 2.291710376739502\n",
      "current loss = 2.305050849914551\n",
      "current loss = 2.3001351356506348\n",
      "current loss = 2.299375057220459\n",
      "current loss = 2.300442695617676\n",
      "current loss = 2.295267105102539\n",
      "current loss = 2.303173542022705\n",
      "current loss = 2.2966723442077637\n",
      "current loss = 2.302471160888672\n",
      "current loss = 2.3046963214874268\n",
      "current loss = 2.3021719455718994\n",
      "current loss = 2.297187089920044\n",
      "current loss = 2.3034307956695557\n",
      "current loss = 2.3024964332580566\n",
      "current loss = 2.3031694889068604\n",
      "current loss = 2.299401044845581\n",
      "current loss = 2.297877073287964\n",
      "current loss = 2.295532464981079\n",
      "current loss = 2.3023321628570557\n",
      "current loss = 2.30462908744812\n",
      "current loss = 2.3024520874023438\n",
      "current loss = 2.307979106903076\n",
      "current loss = 2.2996323108673096\n",
      "current loss = 2.3004753589630127\n",
      "current loss = 2.304673671722412\n",
      "current loss = 2.300994873046875\n",
      "current loss = 2.303804397583008\n",
      "current loss = 2.304370164871216\n",
      "current loss = 2.3010201454162598\n",
      "current loss = 2.3061819076538086\n",
      "current loss = 2.294802188873291\n",
      "current loss = 2.301884889602661\n",
      "current loss = 2.3027703762054443\n",
      "current loss = 2.2924461364746094\n",
      "current loss = 2.3046398162841797\n",
      "current loss = 2.304065227508545\n",
      "current loss = 2.307645559310913\n",
      "current loss = 2.3027641773223877\n",
      "current loss = 2.2985143661499023\n",
      "current loss = 2.3054754734039307\n",
      "current loss = 2.2979204654693604\n",
      "current loss = 2.3039896488189697\n",
      "current loss = 2.298248291015625\n",
      "current loss = 2.299193859100342\n",
      "current loss = 2.304810047149658\n",
      "current loss = 2.2998294830322266\n",
      "current loss = 2.3028085231781006\n",
      "current loss = 2.303759813308716\n",
      "current loss = 2.2933132648468018\n",
      "current loss = 2.306838035583496\n",
      "current loss = 2.296630620956421\n",
      "current loss = 2.291527509689331\n",
      "current loss = 2.2977147102355957\n",
      "current loss = 2.307748556137085\n",
      "current loss = 2.307790994644165\n",
      "current loss = 2.3060696125030518\n",
      "current loss = 2.3023223876953125\n",
      "current loss = 2.302544593811035\n",
      "current loss = 2.293609142303467\n",
      "current loss = 2.3064780235290527\n",
      "current loss = 2.3007025718688965\n",
      "current loss = 2.307182788848877\n",
      "current loss = 2.3064918518066406\n",
      "current loss = 2.300811767578125\n",
      "current loss = 2.302159309387207\n",
      "current loss = 2.30134916305542\n",
      "current loss = 2.30004620552063\n",
      "current loss = 2.295997381210327\n",
      "current loss = 2.304570198059082\n",
      "current loss = 2.2936654090881348\n",
      "current loss = 2.304715156555176\n",
      "current loss = 2.3033816814422607\n",
      "current loss = 2.299583911895752\n",
      "current loss = 2.307373046875\n",
      "current loss = 2.3066556453704834\n",
      "current loss = 2.295048236846924\n",
      "current loss = 2.309770345687866\n",
      "current loss = 2.304368734359741\n",
      "current loss = 2.3002185821533203\n",
      "current loss = 2.3048369884490967\n",
      "current loss = 2.3047611713409424\n",
      "current loss = 2.299496650695801\n",
      "current loss = 2.29825758934021\n",
      "current loss = 2.3015012741088867\n",
      "current loss = 2.3053996562957764\n",
      "current loss = 2.313516139984131\n",
      "current loss = 2.291189670562744\n",
      "current loss = 2.303257942199707\n",
      "current loss = 2.304424285888672\n",
      "current loss = 2.3046207427978516\n",
      "current loss = 2.296339273452759\n",
      "current loss = 2.303744077682495\n",
      "current loss = 2.30928897857666\n",
      "current loss = 2.3022875785827637\n",
      "current loss = 2.3039870262145996\n",
      "current loss = 2.3087668418884277\n",
      "current loss = 2.3048038482666016\n",
      "current loss = 2.310260057449341\n",
      "current loss = 2.2945542335510254\n",
      "current loss = 2.3074817657470703\n",
      "current loss = 2.3004188537597656\n",
      "current loss = 2.301163673400879\n",
      "current loss = 2.3041162490844727\n",
      "current loss = 2.3041980266571045\n",
      "current loss = 2.2999367713928223\n",
      "current loss = 2.2992634773254395\n",
      "current loss = 2.3005175590515137\n",
      "current loss = 2.3026199340820312\n",
      "current loss = 2.304276466369629\n",
      "current loss = 2.3069465160369873\n",
      "current loss = 2.3082923889160156\n",
      "current loss = 2.3063321113586426\n",
      "current loss = 2.301079273223877\n",
      "current loss = 2.3006200790405273\n",
      "current loss = 2.304464101791382\n",
      "current loss = 2.3081932067871094\n",
      "current loss = 2.30116868019104\n",
      "current loss = 2.305171251296997\n",
      "current loss = 2.3024210929870605\n",
      "current loss = 2.3025050163269043\n",
      "current loss = 2.2948179244995117\n",
      "current loss = 2.3101282119750977\n",
      "current loss = 2.3044679164886475\n",
      "current loss = 2.303845167160034\n",
      "current loss = 2.304109573364258\n",
      "current loss = 2.3082997798919678\n",
      "current loss = 2.30326247215271\n",
      "current loss = 2.3040292263031006\n",
      "current loss = 2.296422004699707\n",
      "current loss = 2.297975778579712\n",
      "current loss = 2.3069965839385986\n",
      "current loss = 2.3090972900390625\n",
      "current loss = 2.301130771636963\n",
      "current loss = 2.299806833267212\n",
      "current loss = 2.301774740219116\n",
      "current loss = 2.3011183738708496\n",
      "current loss = 2.299952983856201\n",
      "current loss = 2.29803466796875\n",
      "current loss = 2.3044893741607666\n",
      "current loss = 2.3007171154022217\n",
      "current loss = 2.3002116680145264\n",
      "current loss = 2.3030431270599365\n",
      "current loss = 2.298588991165161\n",
      "current loss = 2.296966552734375\n",
      "current loss = 2.3071281909942627\n",
      "current loss = 2.2998952865600586\n",
      "current loss = 2.3004560470581055\n",
      "current loss = 2.2993478775024414\n",
      "current loss = 2.3042871952056885\n",
      "current loss = 2.3036141395568848\n",
      "current loss = 2.3011679649353027\n",
      "current loss = 2.3074088096618652\n",
      "current loss = 2.3028364181518555\n",
      "current loss = 2.301300048828125\n",
      "current loss = 2.3024098873138428\n",
      "current loss = 2.307593584060669\n",
      "current loss = 2.300544500350952\n",
      "current loss = 2.3039441108703613\n",
      "current loss = 2.2970359325408936\n",
      "current loss = 2.300774574279785\n",
      "current loss = 2.29821515083313\n",
      "current loss = 2.297039031982422\n",
      "current loss = 2.2984068393707275\n",
      "current loss = 2.3042187690734863\n",
      "current loss = 2.3026089668273926\n",
      "current loss = 2.3035964965820312\n",
      "current loss = 2.3008618354797363\n",
      "current loss = 2.3016135692596436\n",
      "current loss = 2.301290988922119\n",
      "current loss = 2.30611515045166\n",
      "current loss = 2.3013393878936768\n",
      "current loss = 2.30413556098938\n",
      "current loss = 2.3090410232543945\n",
      "current loss = 2.305983543395996\n",
      "current loss = 2.299705743789673\n",
      "current loss = 2.3057730197906494\n",
      "current loss = 2.306872844696045\n",
      "current loss = 2.305116653442383\n",
      "current loss = 2.2977137565612793\n",
      "current loss = 2.296830654144287\n",
      "current loss = 2.3038690090179443\n",
      "current loss = 2.302712917327881\n",
      "current loss = 2.30908203125\n",
      "current loss = 2.3046746253967285\n",
      "current loss = 2.2953784465789795\n",
      "current loss = 2.302800178527832\n",
      "current loss = 2.3035640716552734\n",
      "current loss = 2.297170639038086\n",
      "current loss = 2.29435396194458\n",
      "current loss = 2.303145408630371\n",
      "current loss = 2.301481246948242\n",
      "current loss = 2.3114702701568604\n",
      "current loss = 2.3029861450195312\n",
      "current loss = 2.301413059234619\n",
      "current loss = 2.3075149059295654\n",
      "current loss = 2.3067452907562256\n",
      "current loss = 2.3046419620513916\n",
      "current loss = 2.299502372741699\n",
      "current loss = 2.3026766777038574\n",
      "current loss = 2.2988698482513428\n",
      "current loss = 2.29909348487854\n",
      "current loss = 2.30300235748291\n",
      "current loss = 2.3031513690948486\n",
      "current loss = 2.3037664890289307\n",
      "current loss = 2.2970545291900635\n",
      "current loss = 2.3017382621765137\n",
      "current loss = 2.306265354156494\n",
      "current loss = 2.3062219619750977\n",
      "current loss = 2.3005685806274414\n",
      "current loss = 2.3047971725463867\n",
      "current loss = 2.3050153255462646\n",
      "current loss = 2.2987210750579834\n",
      "current loss = 2.299820899963379\n",
      "current loss = 2.300179958343506\n",
      "current loss = 2.298400640487671\n",
      "current loss = 2.296807289123535\n",
      "current loss = 2.3062570095062256\n",
      "current loss = 2.29836106300354\n",
      "current loss = 2.3009350299835205\n",
      "current loss = 2.3016858100891113\n",
      "current loss = 2.3043625354766846\n",
      "current loss = 2.304992198944092\n",
      "current loss = 2.3043367862701416\n",
      "current loss = 2.3094019889831543\n",
      "current loss = 2.2988173961639404\n",
      "current loss = 2.306891441345215\n",
      "current loss = 2.2978200912475586\n",
      "current loss = 2.2995738983154297\n",
      "current loss = 2.2985246181488037\n",
      "current loss = 2.298471689224243\n",
      "current loss = 2.3063318729400635\n",
      "current loss = 2.2951693534851074\n",
      "current loss = 2.300368547439575\n",
      "current loss = 2.30798602104187\n",
      "current loss = 2.312352418899536\n",
      "current loss = 2.3033881187438965\n",
      "current loss = 2.3021080493927\n",
      "current loss = 2.297417640686035\n",
      "current loss = 2.2953665256500244\n",
      "current loss = 2.2961206436157227\n",
      "current loss = 2.306326150894165\n",
      "current loss = 2.300893783569336\n",
      "current loss = 2.306349754333496\n",
      "current loss = 2.300574541091919\n",
      "current loss = 2.3054845333099365\n",
      "current loss = 2.3000168800354004\n",
      "current loss = 2.300393581390381\n",
      "current loss = 2.3039870262145996\n",
      "current loss = 2.304358720779419\n",
      "current loss = 2.309223175048828\n",
      "current loss = 2.3043863773345947\n",
      "current loss = 2.300321102142334\n",
      "current loss = 2.309906482696533\n",
      "current loss = 2.307354211807251\n",
      "current loss = 2.297318696975708\n",
      "current loss = 2.303025484085083\n",
      "current loss = 2.3031165599823\n",
      "current loss = 2.305361270904541\n",
      "current loss = 2.310028553009033\n",
      "current loss = 2.3037829399108887\n",
      "current loss = 2.298236131668091\n",
      "current loss = 2.2967300415039062\n",
      "current loss = 2.29844331741333\n",
      "current loss = 2.306886672973633\n",
      "current loss = 2.303987503051758\n",
      "current loss = 2.3051419258117676\n",
      "current loss = 2.2955384254455566\n",
      "current loss = 2.3108901977539062\n",
      "current loss = 2.302129030227661\n",
      "current loss = 2.298659324645996\n",
      "current loss = 2.2989983558654785\n",
      "current loss = 2.3003153800964355\n",
      "current loss = 2.306061029434204\n",
      "current loss = 2.302433490753174\n",
      "current loss = 2.304290771484375\n",
      "current loss = 2.299848794937134\n",
      "current loss = 2.301405429840088\n",
      "current loss = 2.3027312755584717\n",
      "current loss = 2.301332473754883\n",
      "current loss = 2.2993648052215576\n",
      "current loss = 2.298851728439331\n",
      "current loss = 2.303257942199707\n",
      "current loss = 2.298316478729248\n",
      "current loss = 2.304454803466797\n",
      "current loss = 2.2975821495056152\n",
      "current loss = 2.299548387527466\n",
      "current loss = 2.302081823348999\n",
      "current loss = 2.3029253482818604\n",
      "current loss = 2.3047573566436768\n",
      "current loss = 2.2996158599853516\n",
      "current loss = 2.3063533306121826\n",
      "current loss = 2.3024396896362305\n",
      "current loss = 2.297170639038086\n",
      "current loss = 2.3039751052856445\n",
      "current loss = 2.299376964569092\n",
      "current loss = 2.3011348247528076\n",
      "current loss = 2.3066585063934326\n",
      "current loss = 2.2987325191497803\n",
      "current loss = 2.2977733612060547\n",
      "current loss = 2.3030924797058105\n",
      "current loss = 2.3037993907928467\n",
      "current loss = 2.305659294128418\n",
      "current loss = 2.29713773727417\n",
      "current loss = 2.295750856399536\n",
      "current loss = 2.303084135055542\n",
      "current loss = 2.3030591011047363\n",
      "current loss = 2.297640562057495\n",
      "current loss = 2.300708055496216\n",
      "current loss = 2.298938512802124\n",
      "current loss = 2.309047222137451\n",
      "current loss = 2.2958297729492188\n",
      "current loss = 2.3024802207946777\n",
      "current loss = 2.298738718032837\n",
      "current loss = 2.3079397678375244\n",
      "current loss = 2.306067705154419\n",
      "current loss = 2.301567792892456\n",
      "current loss = 2.3062844276428223\n",
      "current loss = 2.2999391555786133\n",
      "current loss = 2.3038508892059326\n",
      "current loss = 2.3032054901123047\n",
      "current loss = 2.3004302978515625\n",
      "current loss = 2.3052010536193848\n",
      "current loss = 2.3042073249816895\n",
      "current loss = 2.3064990043640137\n",
      "current loss = 2.298941135406494\n",
      "current loss = 2.3034520149230957\n",
      "current loss = 2.3038346767425537\n",
      "current loss = 2.302459478378296\n",
      "current loss = 2.300060510635376\n",
      "current loss = 2.301844358444214\n",
      "current loss = 2.3006751537323\n",
      "current loss = 2.2949349880218506\n",
      "current loss = 2.301985025405884\n",
      "current loss = 2.2933287620544434\n",
      "current loss = 2.305356025695801\n",
      "current loss = 2.3066346645355225\n",
      "current loss = 2.3032405376434326\n",
      "current loss = 2.309070110321045\n",
      "current loss = 2.2963144779205322\n",
      "current loss = 2.306201934814453\n",
      "current loss = 2.2914154529571533\n",
      "current loss = 2.3039045333862305\n",
      "current loss = 2.3024067878723145\n",
      "current loss = 2.300659418106079\n",
      "current loss = 2.3002238273620605\n",
      "current loss = 2.3042144775390625\n",
      "current loss = 2.2981369495391846\n",
      "current loss = 2.3037240505218506\n",
      "current loss = 2.2998294830322266\n",
      "current loss = 2.2990894317626953\n",
      "current loss = 2.3012216091156006\n",
      "current loss = 2.3086001873016357\n",
      "current loss = 2.297673463821411\n",
      "current loss = 2.3021433353424072\n",
      "current loss = 2.299009323120117\n",
      "current loss = 2.2988336086273193\n",
      "current loss = 2.3047213554382324\n",
      "current loss = 2.3065807819366455\n",
      "current loss = 2.30023455619812\n",
      "current loss = 2.303311347961426\n",
      "current loss = 2.307097911834717\n",
      "current loss = 2.301945209503174\n",
      "current loss = 2.299032688140869\n",
      "current loss = 2.299212694168091\n",
      "current loss = 2.307360887527466\n",
      "current loss = 2.293795585632324\n",
      "current loss = 2.303389072418213\n",
      "current loss = 2.302306652069092\n",
      "current loss = 2.2988698482513428\n",
      "current loss = 2.3076322078704834\n",
      "current loss = 2.3037328720092773\n",
      "current loss = 2.2936577796936035\n",
      "current loss = 2.3012592792510986\n",
      "current loss = 2.294602632522583\n",
      "current loss = 2.2964205741882324\n",
      "current loss = 2.2922732830047607\n",
      "current loss = 2.304131507873535\n",
      "current loss = 2.304628849029541\n",
      "current loss = 2.305068254470825\n",
      "current loss = 2.312650680541992\n",
      "current loss = 2.2981061935424805\n",
      "current loss = 2.304025411605835\n",
      "current loss = 2.301644802093506\n",
      "current loss = 2.3051536083221436\n",
      "current loss = 2.3065545558929443\n",
      "current loss = 2.3021063804626465\n",
      "current loss = 2.305227756500244\n",
      "current loss = 2.302849054336548\n",
      "current loss = 2.301790714263916\n",
      "current loss = 2.3009819984436035\n",
      "current loss = 2.298539400100708\n",
      "current loss = 2.2975008487701416\n",
      "current loss = 2.2956719398498535\n",
      "current loss = 2.3040006160736084\n",
      "current loss = 2.3032243251800537\n",
      "current loss = 2.2989797592163086\n",
      "current loss = 2.293246269226074\n",
      "current loss = 2.29569673538208\n",
      "current loss = 2.2969906330108643\n",
      "current loss = 2.3027684688568115\n",
      "current loss = 2.304237127304077\n",
      "current loss = 2.300271511077881\n",
      "current loss = 2.3034112453460693\n",
      "current loss = 2.297912120819092\n",
      "current loss = 2.2930736541748047\n",
      "current loss = 2.3100955486297607\n",
      "current loss = 2.2932329177856445\n",
      "current loss = 2.3062167167663574\n",
      "current loss = 2.296614646911621\n",
      "current loss = 2.294013023376465\n",
      "current loss = 2.303281784057617\n",
      "current loss = 2.301971912384033\n",
      "current loss = 2.30397891998291\n",
      "current loss = 2.3070452213287354\n",
      "current loss = 2.3076727390289307\n",
      "current loss = 2.3018393516540527\n",
      "current loss = 2.301837682723999\n",
      "current loss = 2.305215358734131\n",
      "current loss = 2.3121652603149414\n",
      "current loss = 2.2950987815856934\n",
      "current loss = 2.3019814491271973\n",
      "current loss = 2.3038272857666016\n",
      "current loss = 2.3096349239349365\n",
      "current loss = 2.2980175018310547\n",
      "current loss = 2.302868604660034\n",
      "current loss = 2.3019185066223145\n",
      "current loss = 2.2989563941955566\n",
      "current loss = 2.3065192699432373\n",
      "current loss = 2.2977890968322754\n",
      "current loss = 2.306626796722412\n",
      "current loss = 2.299558401107788\n",
      "current loss = 2.298346519470215\n",
      "current loss = 2.310608148574829\n",
      "current loss = 2.309695243835449\n",
      "current loss = 2.2997922897338867\n",
      "current loss = 2.3018171787261963\n",
      "current loss = 2.294834613800049\n",
      "current loss = 2.305835723876953\n",
      "current loss = 2.3081796169281006\n",
      "current loss = 2.297062397003174\n",
      "current loss = 2.30769681930542\n",
      "current loss = 2.3011062145233154\n",
      "current loss = 2.3053014278411865\n",
      "current loss = 2.30277681350708\n",
      "current loss = 2.306851387023926\n",
      "current loss = 2.3031680583953857\n",
      "current loss = 2.299257278442383\n",
      "current loss = 2.3033595085144043\n",
      "current loss = 2.2989978790283203\n",
      "current loss = 2.30007004737854\n",
      "current loss = 2.306730031967163\n",
      "current loss = 2.3017635345458984\n",
      "current loss = 2.29384183883667\n",
      "current loss = 2.303297758102417\n",
      "current loss = 2.307384729385376\n",
      "current loss = 2.3064775466918945\n",
      "current loss = 2.301569700241089\n",
      "current loss = 2.304062843322754\n",
      "current loss = 2.3072385787963867\n",
      "current loss = 2.2974460124969482\n",
      "current loss = 2.3045310974121094\n",
      "current loss = 2.3017988204956055\n",
      "current loss = 2.2950711250305176\n",
      "current loss = 2.3040947914123535\n",
      "current loss = 2.2973945140838623\n",
      "current loss = 2.3013651371002197\n",
      "current loss = 2.2965550422668457\n",
      "current loss = 2.298933267593384\n",
      "current loss = 2.2962660789489746\n",
      "current loss = 2.297543525695801\n",
      "current loss = 2.303009271621704\n",
      "current loss = 2.302177667617798\n",
      "current loss = 2.300595283508301\n",
      "current loss = 2.2977659702301025\n",
      "current loss = 2.2957804203033447\n",
      "current loss = 2.2970616817474365\n",
      "current loss = 2.3017616271972656\n",
      "current loss = 2.3030409812927246\n",
      "current loss = 2.298002004623413\n",
      "current loss = 2.301408290863037\n",
      "current loss = 2.299839973449707\n",
      "current loss = 2.2935092449188232\n",
      "current loss = 2.3004045486450195\n",
      "current loss = 2.305450201034546\n",
      "current loss = 2.3052978515625\n",
      "current loss = 2.2979910373687744\n",
      "current loss = 2.294863224029541\n",
      "current loss = 2.3047666549682617\n",
      "current loss = 2.2951457500457764\n",
      "current loss = 2.294703245162964\n",
      "current loss = 2.2946979999542236\n",
      "current loss = 2.3019602298736572\n",
      "current loss = 2.30509614944458\n",
      "current loss = 2.295640707015991\n",
      "current loss = 2.307863235473633\n",
      "current loss = 2.298837184906006\n",
      "current loss = 2.3004584312438965\n",
      "current loss = 2.2859301567077637\n",
      "current loss = 2.295804262161255\n",
      "current loss = 2.293776035308838\n",
      "current loss = 2.3032493591308594\n",
      "current loss = 2.3039774894714355\n",
      "current loss = 2.3065953254699707\n",
      "current loss = 2.3055500984191895\n",
      "current loss = 2.2990081310272217\n",
      "current loss = 2.307504177093506\n",
      "current loss = 2.2928905487060547\n",
      "current loss = 2.3136777877807617\n",
      "current loss = 2.2898688316345215\n",
      "current loss = 2.3043646812438965\n",
      "current loss = 2.308006525039673\n",
      "current loss = 2.307952880859375\n",
      "current loss = 2.3007843494415283\n",
      "current loss = 2.300400733947754\n",
      "current loss = 2.3063929080963135\n",
      "current loss = 2.308379650115967\n",
      "current loss = 2.3043859004974365\n",
      "current loss = 2.300041913986206\n",
      "current loss = 2.30415678024292\n",
      "current loss = 2.2965002059936523\n",
      "current loss = 2.3063721656799316\n",
      "current loss = 2.2985682487487793\n",
      "current loss = 2.3031363487243652\n",
      "current loss = 2.2978734970092773\n",
      "current loss = 2.3047566413879395\n",
      "current loss = 2.3061318397521973\n",
      "current loss = 2.29996395111084\n",
      "current loss = 2.3103649616241455\n",
      "current loss = 2.3044209480285645\n",
      "current loss = 2.2979938983917236\n",
      "current loss = 2.3066179752349854\n",
      "current loss = 2.303920030593872\n",
      "current loss = 2.2938716411590576\n",
      "current loss = 2.295724868774414\n",
      "current loss = 2.302367687225342\n",
      "current loss = 2.3065345287323\n",
      "current loss = 2.2983193397521973\n",
      "current loss = 2.3005640506744385\n",
      "current loss = 2.306271553039551\n",
      "current loss = 2.2998013496398926\n",
      "current loss = 2.3055601119995117\n",
      "current loss = 2.3024094104766846\n",
      "current loss = 2.307511568069458\n",
      "current loss = 2.309147834777832\n",
      "current loss = 2.3025710582733154\n",
      "current loss = 2.305560350418091\n",
      "current loss = 2.300534963607788\n",
      "current loss = 2.2973339557647705\n",
      "current loss = 2.304859161376953\n",
      "current loss = 2.308969020843506\n",
      "current loss = 2.302983522415161\n",
      "current loss = 2.3026227951049805\n",
      "current loss = 2.302398920059204\n",
      "current loss = 2.300673246383667\n",
      "current loss = 2.2985079288482666\n",
      "current loss = 2.3026232719421387\n",
      "current loss = 2.305720090866089\n",
      "current loss = 2.2992208003997803\n",
      "current loss = 2.3030214309692383\n",
      "current loss = 2.296029806137085\n",
      "current loss = 2.2988011837005615\n",
      "current loss = 2.313077688217163\n",
      "current loss = 2.309999942779541\n",
      "current loss = 2.2957539558410645\n",
      "current loss = 2.312673568725586\n",
      "current loss = 2.30283522605896\n",
      "current loss = 2.3042120933532715\n",
      "current loss = 2.3194539546966553\n",
      "current loss = 2.30562162399292\n",
      "current loss = 2.3028688430786133\n",
      "current loss = 2.3066444396972656\n",
      "current loss = 2.303793430328369\n",
      "current loss = 2.3023362159729004\n",
      "current loss = 2.296123743057251\n",
      "current loss = 2.303788661956787\n",
      "current loss = 2.3018996715545654\n",
      "current loss = 2.2980315685272217\n",
      "current loss = 2.2918663024902344\n",
      "current loss = 2.2965826988220215\n",
      "current loss = 2.2984085083007812\n",
      "current loss = 2.2984700202941895\n",
      "current loss = 2.299297332763672\n",
      "current loss = 2.305903673171997\n",
      "current loss = 2.2976346015930176\n",
      "current loss = 2.293027400970459\n",
      "current loss = 2.298055410385132\n",
      "current loss = 2.299924850463867\n",
      "current loss = 2.302381753921509\n",
      "current loss = 2.3089232444763184\n",
      "current loss = 2.303042411804199\n",
      "current loss = 2.2934865951538086\n",
      "current loss = 2.307297468185425\n",
      "current loss = 2.303644895553589\n",
      "current loss = 2.30378794670105\n",
      "current loss = 2.2939302921295166\n",
      "current loss = 2.3043372631073\n",
      "current loss = 2.302635431289673\n",
      "current loss = 2.303711175918579\n",
      "current loss = 2.297053337097168\n",
      "current loss = 2.2946367263793945\n",
      "current loss = 2.301903486251831\n",
      "current loss = 2.2981150150299072\n",
      "current loss = 2.3030200004577637\n",
      "current loss = 2.299842119216919\n",
      "current loss = 2.3002731800079346\n",
      "current loss = 2.305518865585327\n",
      "current loss = 2.307981252670288\n",
      "current loss = 2.3070287704467773\n",
      "current loss = 2.3047678470611572\n",
      "current loss = 2.304450750350952\n",
      "current loss = 2.301023483276367\n",
      "current loss = 2.3082275390625\n",
      "current loss = 2.3024821281433105\n",
      "current loss = 2.293041229248047\n",
      "current loss = 2.2969858646392822\n",
      "current loss = 2.3094184398651123\n",
      "current loss = 2.304056406021118\n",
      "current loss = 2.3120880126953125\n",
      "current loss = 2.3092708587646484\n",
      "current loss = 2.295206069946289\n",
      "current loss = 2.3069097995758057\n",
      "current loss = 2.3044068813323975\n",
      "current loss = 2.303126096725464\n",
      "current loss = 2.305861711502075\n",
      "current loss = 2.2954821586608887\n",
      "current loss = 2.302436351776123\n",
      "current loss = 2.2999677658081055\n",
      "current loss = 2.2996573448181152\n",
      "current loss = 2.3113696575164795\n",
      "current loss = 2.3068506717681885\n",
      "current loss = 2.3019237518310547\n",
      "current loss = 2.30534291267395\n",
      "current loss = 2.3030645847320557\n",
      "current loss = 2.3060460090637207\n",
      "current loss = 2.299678325653076\n",
      "current loss = 2.293959140777588\n",
      "current loss = 2.2972750663757324\n",
      "current loss = 2.3043365478515625\n",
      "current loss = 2.3004062175750732\n",
      "current loss = 2.299663782119751\n",
      "current loss = 2.303297996520996\n",
      "current loss = 2.296755075454712\n",
      "current loss = 2.302201747894287\n",
      "current loss = 2.296916961669922\n",
      "current loss = 2.3042807579040527\n",
      "current loss = 2.3052377700805664\n",
      "current loss = 2.3069379329681396\n",
      "current loss = 2.305349111557007\n",
      "current loss = 2.2984392642974854\n",
      "current loss = 2.299811840057373\n",
      "current loss = 2.3019027709960938\n",
      "current loss = 2.305053472518921\n",
      "current loss = 2.294626474380493\n",
      "current loss = 2.2992982864379883\n",
      "current loss = 2.293853282928467\n",
      "current loss = 2.2944204807281494\n",
      "current loss = 2.3026928901672363\n",
      "current loss = 2.2988762855529785\n",
      "current loss = 2.3098676204681396\n",
      "current loss = 2.307481527328491\n",
      "current loss = 2.302872657775879\n",
      "current loss = 2.2993273735046387\n",
      "current loss = 2.303593873977661\n",
      "current loss = 2.299375295639038\n",
      "current loss = 2.312896966934204\n",
      "current loss = 2.296924352645874\n",
      "current loss = 2.3049190044403076\n",
      "current loss = 2.304387331008911\n",
      "current loss = 2.3040714263916016\n",
      "current loss = 2.3078994750976562\n",
      "current loss = 2.296038866043091\n",
      "current loss = 2.295668840408325\n",
      "current loss = 2.297522783279419\n",
      "current loss = 2.300039291381836\n",
      "current loss = 2.305438756942749\n",
      "current loss = 2.303548574447632\n",
      "current loss = 2.29428768157959\n",
      "current loss = 2.3054802417755127\n",
      "current loss = 2.307523012161255\n",
      "current loss = 2.2973833084106445\n",
      "current loss = 2.3046650886535645\n",
      "current loss = 2.2975516319274902\n",
      "current loss = 2.3014397621154785\n",
      "current loss = 2.3053925037384033\n",
      "current loss = 2.2978017330169678\n",
      "current loss = 2.30106258392334\n",
      "current loss = 2.29414701461792\n",
      "current loss = 2.2983460426330566\n",
      "current loss = 2.2975637912750244\n",
      "current loss = 2.306110143661499\n",
      "current loss = 2.306406259536743\n",
      "current loss = 2.300628185272217\n",
      "current loss = 2.3012938499450684\n",
      "current loss = 2.299217462539673\n",
      "current loss = 2.3070061206817627\n",
      "current loss = 2.3033087253570557\n",
      "current loss = 2.2978925704956055\n",
      "current loss = 2.295321464538574\n",
      "current loss = 2.3091509342193604\n",
      "current loss = 2.3053030967712402\n",
      "current loss = 2.296823501586914\n",
      "current loss = 2.2996304035186768\n",
      "current loss = 2.3034157752990723\n",
      "current loss = 2.2961342334747314\n",
      "current loss = 2.3035922050476074\n",
      "current loss = 2.299225330352783\n",
      "current loss = 2.3098347187042236\n",
      "current loss = 2.3072593212127686\n",
      "current loss = 2.3047873973846436\n",
      "current loss = 2.3037619590759277\n",
      "current loss = 2.3121776580810547\n",
      "current loss = 2.302612781524658\n",
      "current loss = 2.3044304847717285\n",
      "current loss = 2.3019638061523438\n",
      "current loss = 2.306504726409912\n",
      "current loss = 2.3072702884674072\n",
      "current loss = 2.3023293018341064\n",
      "current loss = 2.295950412750244\n",
      "current loss = 2.3075459003448486\n",
      "current loss = 2.30789852142334\n",
      "current loss = 2.301102876663208\n",
      "current loss = 2.3094100952148438\n",
      "current loss = 2.305837869644165\n",
      "current loss = 2.296933650970459\n",
      "current loss = 2.285369396209717\n",
      "current loss = 2.2961621284484863\n",
      "current loss = 2.3065097332000732\n",
      "current loss = 2.302410364151001\n",
      "current loss = 2.2976996898651123\n",
      "current loss = 2.3020646572113037\n",
      "current loss = 2.308736562728882\n",
      "current loss = 2.302476167678833\n",
      "current loss = 2.292475461959839\n",
      "current loss = 2.2973594665527344\n",
      "current loss = 2.3063719272613525\n",
      "current loss = 2.3045201301574707\n",
      "current loss = 2.296391010284424\n",
      "current loss = 2.306119203567505\n",
      "current loss = 2.296982765197754\n",
      "current loss = 2.298259735107422\n",
      "current loss = 2.308567523956299\n",
      "current loss = 2.295893669128418\n",
      "current loss = 2.3083395957946777\n",
      "current loss = 2.3053717613220215\n",
      "current loss = 2.298823595046997\n",
      "current loss = 2.2947752475738525\n",
      "current loss = 2.300969362258911\n",
      "current loss = 2.307126998901367\n",
      "current loss = 2.2921254634857178\n",
      "current loss = 2.306570291519165\n",
      "current loss = 2.305168867111206\n",
      "current loss = 2.2978575229644775\n",
      "current loss = 2.303956985473633\n",
      "current loss = 2.299567937850952\n",
      "current loss = 2.2987377643585205\n",
      "current loss = 2.302823066711426\n",
      "current loss = 2.29543137550354\n",
      "current loss = 2.3038125038146973\n",
      "current loss = 2.3028650283813477\n",
      "current loss = 2.3005247116088867\n",
      "current loss = 2.302096366882324\n",
      "current loss = 2.3092401027679443\n",
      "current loss = 2.2952170372009277\n",
      "current loss = 2.3102211952209473\n",
      "current loss = 2.302867889404297\n",
      "current loss = 2.302666187286377\n",
      "current loss = 2.3021388053894043\n",
      "current loss = 2.3073201179504395\n",
      "current loss = 2.2998831272125244\n",
      "current loss = 2.2992045879364014\n",
      "current loss = 2.2996420860290527\n",
      "current loss = 2.3013031482696533\n",
      "current loss = 2.3082070350646973\n",
      "current loss = 2.307107925415039\n",
      "current loss = 2.296090841293335\n",
      "current loss = 2.296738624572754\n",
      "current loss = 2.30399751663208\n",
      "current loss = 2.3020668029785156\n",
      "current loss = 2.301936149597168\n",
      "current loss = 2.298276901245117\n",
      "current loss = 2.303568124771118\n",
      "current loss = 2.305988311767578\n",
      "current loss = 2.3079402446746826\n",
      "current loss = 2.301278829574585\n",
      "current loss = 2.305058479309082\n",
      "current loss = 2.3066086769104004\n",
      "current loss = 2.3113410472869873\n",
      "current loss = 2.3021080493927\n",
      "current loss = 2.3036420345306396\n",
      "current loss = 2.300398588180542\n",
      "current loss = 2.300633668899536\n",
      "current loss = 2.3047332763671875\n",
      "current loss = 2.2983574867248535\n",
      "current loss = 2.3094804286956787\n",
      "current loss = 2.299424171447754\n",
      "current loss = 2.2969791889190674\n",
      "current loss = 2.298363208770752\n",
      "current loss = 2.301740884780884\n",
      "current loss = 2.307656764984131\n",
      "current loss = 2.3100297451019287\n",
      "current loss = 2.295271396636963\n",
      "current loss = 2.3009722232818604\n",
      "current loss = 2.3008952140808105\n",
      "current loss = 2.2981197834014893\n",
      "current loss = 2.3034613132476807\n",
      "current loss = 2.3017210960388184\n",
      "current loss = 2.30648136138916\n",
      "current loss = 2.306612730026245\n",
      "current loss = 2.3006410598754883\n",
      "current loss = 2.298116445541382\n",
      "current loss = 2.3062920570373535\n",
      "current loss = 2.3034701347351074\n",
      "current loss = 2.298582077026367\n",
      "current loss = 2.3008389472961426\n",
      "current loss = 2.2965621948242188\n",
      "current loss = 2.2963521480560303\n",
      "current loss = 2.302671432495117\n",
      "current loss = 2.3021657466888428\n",
      "current loss = 2.2980635166168213\n",
      "current loss = 2.3064076900482178\n",
      "current loss = 2.303725242614746\n",
      "current loss = 2.3023178577423096\n",
      "current loss = 2.3084890842437744\n",
      "current loss = 2.3030030727386475\n",
      "current loss = 2.29876971244812\n",
      "current loss = 2.303359270095825\n",
      "current loss = 2.298206329345703\n",
      "current loss = 2.3079447746276855\n",
      "current loss = 2.2979917526245117\n",
      "current loss = 2.304353713989258\n",
      "current loss = 2.3052165508270264\n",
      "current loss = 2.305510997772217\n",
      "current loss = 2.3005177974700928\n",
      "current loss = 2.303549289703369\n",
      "current loss = 2.306076765060425\n",
      "current loss = 2.2980542182922363\n",
      "current loss = 2.3077480792999268\n",
      "current loss = 2.300279378890991\n",
      "current loss = 2.29783296585083\n",
      "current loss = 2.3054757118225098\n",
      "current loss = 2.2995169162750244\n",
      "current loss = 2.303575038909912\n",
      "current loss = 2.305354118347168\n",
      "current loss = 2.294188976287842\n",
      "current loss = 2.3041133880615234\n",
      "current loss = 2.296956777572632\n",
      "current loss = 2.299473285675049\n",
      "current loss = 2.3065783977508545\n",
      "current loss = 2.299205780029297\n",
      "current loss = 2.300264835357666\n",
      "current loss = 2.301983118057251\n",
      "current loss = 2.299586057662964\n",
      "current loss = 2.3029086589813232\n",
      "current loss = 2.305131673812866\n",
      "current loss = 2.2961270809173584\n",
      "current loss = 2.303177833557129\n",
      "current loss = 2.298821210861206\n",
      "current loss = 2.3079030513763428\n",
      "current loss = 2.3031530380249023\n",
      "current loss = 2.3081166744232178\n",
      "current loss = 2.29811954498291\n",
      "current loss = 2.30117130279541\n",
      "current loss = 2.296788215637207\n",
      "current loss = 2.304901361465454\n",
      "current loss = 2.2933332920074463\n",
      "current loss = 2.298459053039551\n",
      "current loss = 2.3036763668060303\n",
      "current loss = 2.2979040145874023\n",
      "current loss = 2.301873207092285\n",
      "current loss = 2.3029732704162598\n",
      "current loss = 2.3043315410614014\n",
      "current loss = 2.3062384128570557\n",
      "current loss = 2.301872968673706\n",
      "current loss = 2.2990574836730957\n",
      "current loss = 2.303663730621338\n",
      "current loss = 2.3040359020233154\n",
      "current loss = 2.302320718765259\n",
      "current loss = 2.3036043643951416\n",
      "current loss = 2.2962772846221924\n",
      "current loss = 2.306135892868042\n",
      "current loss = 2.303107976913452\n",
      "current loss = 2.3037233352661133\n",
      "current loss = 2.299924850463867\n",
      "current loss = 2.3062140941619873\n",
      "current loss = 2.2951080799102783\n",
      "current loss = 2.2968478202819824\n",
      "current loss = 2.3053972721099854\n",
      "current loss = 2.301788806915283\n",
      "current loss = 2.311404228210449\n",
      "current loss = 2.3078551292419434\n",
      "current loss = 2.303387403488159\n",
      "current loss = 2.3011178970336914\n",
      "current loss = 2.2963812351226807\n",
      "current loss = 2.3055689334869385\n",
      "current loss = 2.3003532886505127\n",
      "current loss = 2.3101460933685303\n",
      "current loss = 2.3010411262512207\n",
      "current loss = 2.303624153137207\n",
      "current loss = 2.300705671310425\n",
      "current loss = 2.304625988006592\n",
      "current loss = 2.2927842140197754\n",
      "current loss = 2.305807113647461\n",
      "current loss = 2.301915168762207\n",
      "current loss = 2.30704927444458\n",
      "current loss = 2.304741144180298\n",
      "current loss = 2.306816816329956\n",
      "current loss = 2.296365261077881\n",
      "current loss = 2.301197052001953\n",
      "current loss = 2.2995848655700684\n",
      "current loss = 2.30100679397583\n",
      "current loss = 2.3016884326934814\n",
      "current loss = 2.302557945251465\n",
      "current loss = 2.310546398162842\n",
      "current loss = 2.297067403793335\n",
      "current loss = 2.302504301071167\n",
      "current loss = 2.299616813659668\n",
      "current loss = 2.3007795810699463\n",
      "current loss = 2.299654722213745\n",
      "current loss = 2.3038458824157715\n",
      "current loss = 2.2989847660064697\n",
      "current loss = 2.299729347229004\n",
      "current loss = 2.3017497062683105\n",
      "current loss = 2.2969701290130615\n",
      "current loss = 2.301833391189575\n",
      "current loss = 2.306243896484375\n",
      "current loss = 2.3089869022369385\n",
      "current loss = 2.304286479949951\n",
      "current loss = 2.3038136959075928\n",
      "current loss = 2.302180290222168\n",
      "current loss = 2.29634165763855\n",
      "current loss = 2.302604913711548\n",
      "current loss = 2.3070693016052246\n",
      "current loss = 2.2994980812072754\n",
      "current loss = 2.304560422897339\n",
      "current loss = 2.296651601791382\n",
      "current loss = 2.3088021278381348\n",
      "current loss = 2.307013511657715\n",
      "current loss = 2.300008773803711\n",
      "current loss = 2.3065268993377686\n",
      "current loss = 2.300098180770874\n",
      "current loss = 2.298879861831665\n",
      "current loss = 2.3027830123901367\n",
      "current loss = 2.307058811187744\n",
      "current loss = 2.294513463973999\n",
      "current loss = 2.2993435859680176\n",
      "current loss = 2.3041229248046875\n",
      "current loss = 2.300543785095215\n",
      "current loss = 2.3032805919647217\n",
      "current loss = 2.30212140083313\n",
      "current loss = 2.307377576828003\n",
      "current loss = 2.3040244579315186\n",
      "current loss = 2.304114580154419\n",
      "current loss = 2.2956302165985107\n",
      "current loss = 2.303724527359009\n",
      "current loss = 2.298579454421997\n",
      "current loss = 2.3038549423217773\n",
      "current loss = 2.2983169555664062\n",
      "current loss = 2.302248954772949\n",
      "current loss = 2.3007819652557373\n",
      "current loss = 2.2989344596862793\n",
      "current loss = 2.307033061981201\n",
      "current loss = 2.3022267818450928\n",
      "current loss = 2.2993686199188232\n",
      "current loss = 2.3069307804107666\n",
      "current loss = 2.30134916305542\n",
      "current loss = 2.3017115592956543\n",
      "current loss = 2.3042829036712646\n",
      "current loss = 2.2961366176605225\n",
      "current loss = 2.3016321659088135\n",
      "current loss = 2.296721935272217\n",
      "current loss = 2.3023014068603516\n",
      "current loss = 2.2981133460998535\n",
      "current loss = 2.2990756034851074\n",
      "current loss = 2.305294990539551\n",
      "current loss = 2.2992730140686035\n",
      "current loss = 2.3000786304473877\n",
      "current loss = 2.308131694793701\n",
      "current loss = 2.299637794494629\n",
      "current loss = 2.300544261932373\n",
      "current loss = 2.3023269176483154\n",
      "current loss = 2.302680492401123\n",
      "current loss = 2.294882297515869\n",
      "current loss = 2.3083202838897705\n",
      "current loss = 2.30531644821167\n",
      "current loss = 2.301058053970337\n",
      "current loss = 2.2989776134490967\n",
      "current loss = 2.302793502807617\n",
      "current loss = 2.308023452758789\n",
      "current loss = 2.2968623638153076\n",
      "current loss = 2.2989094257354736\n",
      "current loss = 2.305330514907837\n",
      "current loss = 2.301753282546997\n",
      "current loss = 2.3058927059173584\n",
      "current loss = 2.303083658218384\n",
      "current loss = 2.2967615127563477\n",
      "current loss = 2.30025577545166\n",
      "current loss = 2.3107471466064453\n",
      "current loss = 2.3028852939605713\n",
      "current loss = 2.3024654388427734\n",
      "current loss = 2.2983264923095703\n",
      "current loss = 2.304699659347534\n",
      "current loss = 2.3063580989837646\n",
      "current loss = 2.2997634410858154\n",
      "current loss = 2.2998456954956055\n",
      "current loss = 2.307499408721924\n",
      "current loss = 2.303163528442383\n",
      "current loss = 2.299614191055298\n",
      "current loss = 2.3023176193237305\n",
      "current loss = 2.3076839447021484\n",
      "current loss = 2.297234535217285\n",
      "current loss = 2.3013391494750977\n",
      "current loss = 2.303830623626709\n",
      "current loss = 2.286867141723633\n",
      "current loss = 2.3064844608306885\n",
      "current loss = 2.3011481761932373\n",
      "current loss = 2.301273822784424\n",
      "current loss = 2.30753493309021\n",
      "current loss = 2.3012783527374268\n",
      "current loss = 2.3017587661743164\n",
      "current loss = 2.304675340652466\n",
      "current loss = 2.3028483390808105\n",
      "current loss = 2.3036670684814453\n",
      "current loss = 2.3010895252227783\n",
      "current loss = 2.2971765995025635\n",
      "current loss = 2.302194356918335\n",
      "current loss = 2.3031768798828125\n",
      "current loss = 2.3004727363586426\n",
      "current loss = 2.2994022369384766\n",
      "current loss = 2.3036677837371826\n",
      "current loss = 2.310363292694092\n",
      "current loss = 2.301670551300049\n",
      "current loss = 2.3011505603790283\n",
      "current loss = 2.3035130500793457\n",
      "current loss = 2.2964518070220947\n",
      "current loss = 2.2942380905151367\n",
      "current loss = 2.307487964630127\n",
      "current loss = 2.2999610900878906\n",
      "current loss = 2.3101742267608643\n",
      "current loss = 2.3079028129577637\n",
      "current loss = 2.2982256412506104\n",
      "current loss = 2.3062639236450195\n",
      "current loss = 2.304448366165161\n",
      "current loss = 2.301996946334839\n",
      "current loss = 2.296335220336914\n",
      "current loss = 2.2970447540283203\n",
      "current loss = 2.303234338760376\n",
      "current loss = 2.294562339782715\n",
      "current loss = 2.299013614654541\n",
      "current loss = 2.3016467094421387\n",
      "current loss = 2.2980730533599854\n",
      "current loss = 2.299938917160034\n",
      "current loss = 2.302877187728882\n",
      "current loss = 2.3067753314971924\n",
      "current loss = 2.307990312576294\n",
      "current loss = 2.3000102043151855\n",
      "current loss = 2.30228590965271\n",
      "current loss = 2.299133539199829\n",
      "current loss = 2.304297924041748\n",
      "current loss = 2.3087942600250244\n",
      "current loss = 2.2989559173583984\n",
      "current loss = 2.3016278743743896\n",
      "current loss = 2.303262948989868\n",
      "current loss = 2.3010060787200928\n",
      "current loss = 2.2970409393310547\n",
      "current loss = 2.300283193588257\n",
      "current loss = 2.297050952911377\n",
      "current loss = 2.3038463592529297\n",
      "current loss = 2.2940621376037598\n",
      "current loss = 2.3007991313934326\n",
      "current loss = 2.300642490386963\n",
      "current loss = 2.2987186908721924\n",
      "current loss = 2.3017263412475586\n",
      "current loss = 2.3044660091400146\n",
      "current loss = 2.3019425868988037\n",
      "current loss = 2.2982873916625977\n",
      "current loss = 2.299523115158081\n",
      "current loss = 2.300395965576172\n",
      "current loss = 2.29915714263916\n",
      "current loss = 2.302154064178467\n",
      "current loss = 2.3038692474365234\n",
      "current loss = 2.2971301078796387\n",
      "current loss = 2.298914909362793\n",
      "current loss = 2.303417921066284\n",
      "current loss = 2.308591365814209\n",
      "current loss = 2.304558277130127\n",
      "current loss = 2.3005547523498535\n",
      "current loss = 2.2958602905273438\n",
      "current loss = 2.2965030670166016\n",
      "current loss = 2.304063081741333\n",
      "current loss = 2.301772356033325\n",
      "current loss = 2.2993292808532715\n",
      "current loss = 2.3067777156829834\n",
      "current loss = 2.296867609024048\n",
      "current loss = 2.2983531951904297\n",
      "current loss = 2.3015999794006348\n",
      "current loss = 2.293576240539551\n",
      "current loss = 2.304332733154297\n",
      "current loss = 2.303985834121704\n",
      "current loss = 2.3086485862731934\n",
      "current loss = 2.302722215652466\n",
      "current loss = 2.300424575805664\n",
      "current loss = 2.2911899089813232\n",
      "current loss = 2.305673599243164\n",
      "current loss = 2.3029160499572754\n",
      "current loss = 2.2999372482299805\n",
      "current loss = 2.3038406372070312\n",
      "current loss = 2.300553560256958\n",
      "current loss = 2.2990059852600098\n",
      "current loss = 2.2948694229125977\n",
      "current loss = 2.3016772270202637\n",
      "current loss = 2.296172857284546\n",
      "current loss = 2.3018157482147217\n",
      "current loss = 2.301361322402954\n",
      "current loss = 2.3051822185516357\n",
      "current loss = 2.300246000289917\n",
      "current loss = 2.303328275680542\n",
      "current loss = 2.3031420707702637\n",
      "current loss = 2.3043320178985596\n",
      "current loss = 2.298144817352295\n",
      "current loss = 2.3074519634246826\n",
      "current loss = 2.2962777614593506\n",
      "current loss = 2.303955078125\n",
      "current loss = 2.296848773956299\n",
      "current loss = 2.304612159729004\n",
      "current loss = 2.3029069900512695\n",
      "current loss = 2.3025245666503906\n",
      "current loss = 2.302610158920288\n",
      "current loss = 2.304121494293213\n",
      "current loss = 2.2954728603363037\n",
      "current loss = 2.2960119247436523\n",
      "current loss = 2.307573080062866\n",
      "current loss = 2.300750732421875\n",
      "current loss = 2.30513072013855\n",
      "current loss = 2.302380323410034\n",
      "current loss = 2.2992968559265137\n",
      "current loss = 2.3089358806610107\n",
      "current loss = 2.3043739795684814\n",
      "current loss = 2.3022398948669434\n",
      "current loss = 2.309466600418091\n",
      "current loss = 2.301196813583374\n",
      "current loss = 2.304975986480713\n",
      "current loss = 2.2959401607513428\n",
      "current loss = 2.3098700046539307\n",
      "current loss = 2.2903494834899902\n",
      "current loss = 2.300060987472534\n",
      "current loss = 2.2983620166778564\n",
      "current loss = 2.299288034439087\n",
      "current loss = 2.2959213256835938\n",
      "current loss = 2.3021974563598633\n",
      "current loss = 2.3007125854492188\n",
      "current loss = 2.304020643234253\n",
      "current loss = 2.3054935932159424\n",
      "current loss = 2.3024513721466064\n",
      "current loss = 2.313002109527588\n",
      "current loss = 2.2997045516967773\n",
      "current loss = 2.301283121109009\n",
      "current loss = 2.2961044311523438\n",
      "current loss = 2.2984540462493896\n",
      "current loss = 2.301162004470825\n",
      "current loss = 2.3026137351989746\n",
      "current loss = 2.2984580993652344\n",
      "current loss = 2.293205738067627\n",
      "current loss = 2.302474021911621\n",
      "current loss = 2.3016088008880615\n",
      "current loss = 2.290046215057373\n",
      "current loss = 2.2946553230285645\n",
      "current loss = 2.2982866764068604\n",
      "current loss = 2.299412727355957\n",
      "current loss = 2.3012239933013916\n",
      "current loss = 2.30012583732605\n",
      "current loss = 2.292579174041748\n",
      "current loss = 2.3100576400756836\n",
      "current loss = 2.303757429122925\n",
      "current loss = 2.303812265396118\n",
      "current loss = 2.3067100048065186\n",
      "current loss = 2.29927396774292\n",
      "current loss = 2.3052704334259033\n",
      "current loss = 2.3050942420959473\n",
      "current loss = 2.305448055267334\n",
      "current loss = 2.297581434249878\n",
      "current loss = 2.308769464492798\n",
      "current loss = 2.3077194690704346\n",
      "current loss = 2.3103911876678467\n",
      "current loss = 2.3003273010253906\n",
      "current loss = 2.3111391067504883\n",
      "current loss = 2.3049464225769043\n",
      "current loss = 2.2964718341827393\n",
      "current loss = 2.300567388534546\n",
      "current loss = 2.296395778656006\n",
      "current loss = 2.3056037425994873\n",
      "current loss = 2.2947189807891846\n",
      "current loss = 2.304685592651367\n",
      "current loss = 2.301905870437622\n",
      "current loss = 2.298920154571533\n",
      "current loss = 2.3002498149871826\n",
      "current loss = 2.3006086349487305\n",
      "current loss = 2.30244779586792\n",
      "current loss = 2.2983784675598145\n",
      "current loss = 2.3027501106262207\n",
      "current loss = 2.3009374141693115\n",
      "current loss = 2.2972562313079834\n",
      "current loss = 2.304253101348877\n",
      "current loss = 2.3088643550872803\n",
      "current loss = 2.3102447986602783\n",
      "current loss = 2.29727840423584\n",
      "current loss = 2.307777166366577\n",
      "current loss = 2.299891710281372\n",
      "current loss = 2.3075501918792725\n",
      "current loss = 2.3095407485961914\n",
      "current loss = 2.3039042949676514\n",
      "current loss = 2.3130526542663574\n",
      "current loss = 2.3005871772766113\n",
      "current loss = 2.312234401702881\n",
      "current loss = 2.2968103885650635\n",
      "current loss = 2.2964625358581543\n",
      "current loss = 2.3049588203430176\n",
      "current loss = 2.3029253482818604\n",
      "current loss = 2.307452440261841\n",
      "current loss = 2.2938129901885986\n",
      "current loss = 2.2993171215057373\n",
      "current loss = 2.295199155807495\n",
      "current loss = 2.3030402660369873\n",
      "current loss = 2.2968461513519287\n",
      "current loss = 2.3021762371063232\n",
      "current loss = 2.302151679992676\n",
      "current loss = 2.3066306114196777\n",
      "current loss = 2.299919366836548\n",
      "current loss = 2.302037477493286\n",
      "current loss = 2.3027281761169434\n",
      "current loss = 2.3062283992767334\n",
      "current loss = 2.3066389560699463\n",
      "current loss = 2.2995474338531494\n",
      "current loss = 2.3054137229919434\n",
      "current loss = 2.302600860595703\n",
      "current loss = 2.3066766262054443\n",
      "current loss = 2.2975099086761475\n",
      "current loss = 2.303931474685669\n",
      "current loss = 2.303041458129883\n",
      "current loss = 2.305691719055176\n",
      "current loss = 2.2986581325531006\n",
      "current loss = 2.3058555126190186\n",
      "current loss = 2.298466444015503\n",
      "current loss = 2.3037161827087402\n",
      "current loss = 2.302854299545288\n",
      "current loss = 2.299813747406006\n",
      "current loss = 2.2958662509918213\n",
      "current loss = 2.3054070472717285\n",
      "current loss = 2.307863712310791\n",
      "current loss = 2.3023993968963623\n",
      "current loss = 2.3037490844726562\n",
      "current loss = 2.300827741622925\n",
      "current loss = 2.293440818786621\n",
      "current loss = 2.3076581954956055\n",
      "current loss = 2.3069517612457275\n",
      "current loss = 2.3052008152008057\n",
      "current loss = 2.3029632568359375\n",
      "current loss = 2.3008172512054443\n",
      "current loss = 2.2994680404663086\n",
      "current loss = 2.297320604324341\n",
      "current loss = 2.3065004348754883\n",
      "current loss = 2.2978334426879883\n",
      "current loss = 2.308455467224121\n",
      "current loss = 2.3046693801879883\n",
      "current loss = 2.299957752227783\n",
      "current loss = 2.2967357635498047\n",
      "current loss = 2.294724225997925\n",
      "current loss = 2.3043742179870605\n",
      "current loss = 2.297384738922119\n",
      "current loss = 2.3022818565368652\n",
      "current loss = 2.3005611896514893\n",
      "current loss = 2.3014004230499268\n",
      "current loss = 2.301037549972534\n",
      "current loss = 2.3011226654052734\n",
      "current loss = 2.3046131134033203\n",
      "current loss = 2.301654577255249\n",
      "current loss = 2.3084301948547363\n",
      "current loss = 2.2996039390563965\n",
      "current loss = 2.2995874881744385\n",
      "current loss = 2.3049771785736084\n",
      "current loss = 2.305921792984009\n",
      "current loss = 2.29984188079834\n",
      "current loss = 2.300869941711426\n",
      "current loss = 2.300265073776245\n",
      "current loss = 2.3016605377197266\n",
      "current loss = 2.3017923831939697\n",
      "current loss = 2.301929235458374\n",
      "current loss = 2.3063602447509766\n",
      "current loss = 2.3023171424865723\n",
      "current loss = 2.3039402961730957\n",
      "current loss = 2.2985124588012695\n",
      "current loss = 2.30734920501709\n",
      "current loss = 2.299912452697754\n",
      "current loss = 2.3093650341033936\n",
      "current loss = 2.2987637519836426\n",
      "current loss = 2.306196451187134\n",
      "current loss = 2.2972357273101807\n",
      "current loss = 2.301119804382324\n",
      "current loss = 2.2982606887817383\n",
      "current loss = 2.299349546432495\n",
      "current loss = 2.3020002841949463\n",
      "current loss = 2.300276279449463\n",
      "current loss = 2.295525074005127\n",
      "current loss = 2.30381178855896\n",
      "current loss = 2.2983133792877197\n",
      "current loss = 2.3014745712280273\n",
      "current loss = 2.299323320388794\n",
      "current loss = 2.296099901199341\n",
      "current loss = 2.305570363998413\n",
      "current loss = 2.305915355682373\n",
      "current loss = 2.3075551986694336\n",
      "current loss = 2.285435914993286\n",
      "current loss = 2.298504114151001\n",
      "current loss = 2.3018267154693604\n",
      "current loss = 2.302525758743286\n",
      "current loss = 2.3052055835723877\n",
      "current loss = 2.301272392272949\n",
      "current loss = 2.303854465484619\n",
      "current loss = 2.299801826477051\n",
      "current loss = 2.298964262008667\n",
      "current loss = 2.3081326484680176\n",
      "current loss = 2.3000705242156982\n",
      "current loss = 2.3011770248413086\n",
      "current loss = 2.3050901889801025\n",
      "current loss = 2.307119131088257\n",
      "current loss = 2.304884195327759\n",
      "current loss = 2.2988078594207764\n",
      "current loss = 2.3023343086242676\n",
      "current loss = 2.2970693111419678\n",
      "current loss = 2.2935070991516113\n",
      "current loss = 2.300493001937866\n",
      "current loss = 2.2971034049987793\n",
      "current loss = 2.2944247722625732\n",
      "current loss = 2.3072643280029297\n",
      "current loss = 2.2971227169036865\n",
      "current loss = 2.3062098026275635\n",
      "current loss = 2.3021225929260254\n",
      "current loss = 2.302870035171509\n",
      "current loss = 2.3081893920898438\n",
      "current loss = 2.2980329990386963\n",
      "current loss = 2.297825336456299\n",
      "current loss = 2.304675579071045\n",
      "current loss = 2.302154302597046\n",
      "current loss = 2.3030905723571777\n",
      "current loss = 2.300178050994873\n",
      "current loss = 2.3078179359436035\n",
      "current loss = 2.304854393005371\n",
      "current loss = 2.3075311183929443\n",
      "current loss = 2.2979416847229004\n",
      "current loss = 2.308474540710449\n",
      "current loss = 2.303729295730591\n",
      "current loss = 2.2998266220092773\n",
      "current loss = 2.295975685119629\n",
      "current loss = 2.3058807849884033\n",
      "current loss = 2.296046257019043\n",
      "current loss = 2.301862955093384\n",
      "current loss = 2.3013391494750977\n",
      "current loss = 2.3029263019561768\n",
      "current loss = 2.2987446784973145\n",
      "current loss = 2.3027548789978027\n",
      "current loss = 2.2955875396728516\n",
      "current loss = 2.29709529876709\n",
      "current loss = 2.3048276901245117\n",
      "current loss = 2.302881956100464\n",
      "current loss = 2.297924757003784\n",
      "current loss = 2.3019702434539795\n",
      "current loss = 2.2963569164276123\n",
      "current loss = 2.3036553859710693\n",
      "current loss = 2.29970645904541\n",
      "current loss = 2.305492401123047\n",
      "current loss = 2.2995786666870117\n",
      "current loss = 2.3011889457702637\n",
      "current loss = 2.304935932159424\n",
      "current loss = 2.304987907409668\n",
      "current loss = 2.3000359535217285\n",
      "current loss = 2.3009374141693115\n",
      "current loss = 2.301722288131714\n",
      "current loss = 2.3011157512664795\n",
      "current loss = 2.3062117099761963\n",
      "current loss = 2.300976276397705\n",
      "current loss = 2.301903247833252\n",
      "current loss = 2.294401168823242\n",
      "current loss = 2.303619861602783\n",
      "current loss = 2.2973392009735107\n",
      "current loss = 2.3052072525024414\n",
      "current loss = 2.302278995513916\n",
      "current loss = 2.3031606674194336\n",
      "current loss = 2.3043253421783447\n",
      "current loss = 2.30635666847229\n",
      "current loss = 2.304586410522461\n",
      "current loss = 2.3061790466308594\n",
      "current loss = 2.3015716075897217\n",
      "current loss = 2.3071911334991455\n",
      "current loss = 2.2998971939086914\n",
      "current loss = 2.300723075866699\n",
      "current loss = 2.299525737762451\n",
      "current loss = 2.299006223678589\n",
      "current loss = 2.2982177734375\n",
      "current loss = 2.3004660606384277\n",
      "current loss = 2.305037260055542\n",
      "current loss = 2.302724838256836\n",
      "current loss = 2.302619457244873\n",
      "current loss = 2.3034772872924805\n",
      "current loss = 2.2992048263549805\n",
      "current loss = 2.3026413917541504\n",
      "current loss = 2.2954351902008057\n",
      "current loss = 2.3052093982696533\n",
      "current loss = 2.2951130867004395\n",
      "current loss = 2.3010802268981934\n",
      "current loss = 2.2951865196228027\n",
      "current loss = 2.2974250316619873\n",
      "current loss = 2.3008298873901367\n",
      "current loss = 2.301633596420288\n",
      "current loss = 2.3054890632629395\n",
      "current loss = 2.301825761795044\n",
      "current loss = 2.302241325378418\n",
      "current loss = 2.2934141159057617\n",
      "current loss = 2.2972524166107178\n",
      "current loss = 2.2987890243530273\n",
      "current loss = 2.301791191101074\n",
      "current loss = 2.3019275665283203\n",
      "current loss = 2.299654006958008\n",
      "current loss = 2.3009517192840576\n",
      "current loss = 2.297898054122925\n",
      "current loss = 2.306497812271118\n",
      "current loss = 2.3095438480377197\n",
      "current loss = 2.3119726181030273\n",
      "current loss = 2.304086685180664\n",
      "current loss = 2.3074111938476562\n",
      "current loss = 2.3059260845184326\n",
      "current loss = 2.299036741256714\n",
      "current loss = 2.2944982051849365\n",
      "current loss = 2.2994797229766846\n",
      "current loss = 2.304802894592285\n",
      "current loss = 2.306635618209839\n",
      "current loss = 2.3021039962768555\n",
      "current loss = 2.304877281188965\n",
      "current loss = 2.3002383708953857\n",
      "current loss = 2.2948355674743652\n",
      "current loss = 2.302703619003296\n",
      "current loss = 2.2931525707244873\n",
      "current loss = 2.297351598739624\n",
      "current loss = 2.3029444217681885\n",
      "current loss = 2.29813289642334\n",
      "current loss = 2.3064780235290527\n",
      "current loss = 2.2972817420959473\n",
      "current loss = 2.2948591709136963\n",
      "current loss = 2.303408145904541\n",
      "current loss = 2.300784111022949\n",
      "current loss = 2.299138069152832\n",
      "current loss = 2.3069865703582764\n",
      "current loss = 2.2978904247283936\n",
      "current loss = 2.3013620376586914\n",
      "current loss = 2.3009214401245117\n",
      "current loss = 2.295841932296753\n",
      "current loss = 2.3002424240112305\n",
      "current loss = 2.3052403926849365\n",
      "current loss = 2.308105945587158\n",
      "current loss = 2.3041114807128906\n",
      "current loss = 2.3083384037017822\n",
      "current loss = 2.306663990020752\n",
      "current loss = 2.2980666160583496\n",
      "current loss = 2.2994673252105713\n",
      "current loss = 2.3052124977111816\n",
      "current loss = 2.2978625297546387\n",
      "current loss = 2.3026533126831055\n",
      "current loss = 2.2976436614990234\n",
      "current loss = 2.3017988204956055\n",
      "current loss = 2.308859348297119\n",
      "current loss = 2.300807237625122\n",
      "current loss = 2.2986466884613037\n",
      "current loss = 2.2981834411621094\n",
      "current loss = 2.3051087856292725\n",
      "current loss = 2.3016550540924072\n",
      "current loss = 2.301793098449707\n",
      "current loss = 2.2994799613952637\n",
      "current loss = 2.3000876903533936\n",
      "current loss = 2.308309316635132\n",
      "current loss = 2.2938578128814697\n",
      "current loss = 2.3044066429138184\n",
      "current loss = 2.297813892364502\n",
      "current loss = 2.297740936279297\n",
      "current loss = 2.3092494010925293\n",
      "current loss = 2.305633306503296\n",
      "current loss = 2.307124376296997\n",
      "current loss = 2.3032004833221436\n",
      "current loss = 2.309114694595337\n",
      "current loss = 2.297506093978882\n",
      "current loss = 2.3012454509735107\n",
      "current loss = 2.3021106719970703\n",
      "current loss = 2.302966356277466\n",
      "current loss = 2.2977843284606934\n",
      "current loss = 2.3124446868896484\n",
      "current loss = 2.3008172512054443\n",
      "current loss = 2.303407669067383\n",
      "current loss = 2.2990550994873047\n",
      "current loss = 2.3025288581848145\n",
      "current loss = 2.2956371307373047\n",
      "current loss = 2.299987316131592\n",
      "current loss = 2.308607339859009\n",
      "current loss = 2.3029210567474365\n",
      "current loss = 2.3028855323791504\n",
      "current loss = 2.3040506839752197\n",
      "current loss = 2.301123857498169\n",
      "current loss = 2.2985894680023193\n",
      "current loss = 2.3003320693969727\n",
      "current loss = 2.299877166748047\n",
      "current loss = 2.305133104324341\n",
      "current loss = 2.2963919639587402\n",
      "current loss = 2.298074960708618\n",
      "current loss = 2.305354595184326\n",
      "current loss = 2.3116698265075684\n",
      "current loss = 2.3052146434783936\n",
      "current loss = 2.301544427871704\n",
      "current loss = 2.303438425064087\n",
      "current loss = 2.3010201454162598\n",
      "current loss = 2.30397367477417\n",
      "current loss = 2.301330327987671\n",
      "current loss = 2.300091028213501\n",
      "current loss = 2.2996959686279297\n",
      "current loss = 2.3043618202209473\n",
      "current loss = 2.2983360290527344\n",
      "current loss = 2.3076326847076416\n",
      "current loss = 2.296773910522461\n",
      "current loss = 2.301807403564453\n",
      "current loss = 2.306835412979126\n",
      "current loss = 2.2995522022247314\n",
      "current loss = 2.3072121143341064\n",
      "current loss = 2.298448324203491\n",
      "current loss = 2.299668312072754\n",
      "current loss = 2.300144672393799\n",
      "current loss = 2.2998580932617188\n",
      "current loss = 2.299199104309082\n",
      "current loss = 2.3019745349884033\n",
      "current loss = 2.299295425415039\n",
      "current loss = 2.3047428131103516\n",
      "current loss = 2.2921555042266846\n",
      "current loss = 2.301490545272827\n",
      "current loss = 2.2967910766601562\n",
      "current loss = 2.299818992614746\n",
      "current loss = 2.307457208633423\n",
      "current loss = 2.2993903160095215\n",
      "current loss = 2.300379991531372\n",
      "current loss = 2.301740884780884\n",
      "current loss = 2.2982521057128906\n",
      "current loss = 2.2988650798797607\n",
      "current loss = 2.303990602493286\n",
      "current loss = 2.306222438812256\n",
      "epoch:2\n",
      "epoch:3\n",
      "epoch:4\n",
      "epoch:5\n",
      "epoch:6\n",
      "epoch:7\n",
      "epoch:8\n",
      "epoch:9\n",
      "epoch:10\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "my_alexnet.to(device)\n",
    "my_alexnet.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"epoch:{epoch+1}\")\n",
    "    #返回 索引 及值！\n",
    "    for idx, (img,label) in enumerate(train_dataloader):\n",
    "        #图片放cpu!!!\n",
    "        images =  img.to(device)\n",
    "        labels = label.to(device)\n",
    "        #print(images.shape)\n",
    "        output = my_alexnet(images)\n",
    "        #print(output)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if epoch % 10000 == 0:\n",
    "            print(f\"current loss = { loss.item()}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Project\\pythonProject\\CV\\Week5\\torch.ipynb 单元格 22\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project/pythonProject/CV/Week5/torch.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m my_alexnet\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project/pythonProject/CV/Week5/torch.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m my_alexnet\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Project/pythonProject/CV/Week5/torch.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m image,label \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project/pythonProject/CV/Week5/torch.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (img,label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project/pythonProject/CV/Week5/torch.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         images \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\23197\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\23197\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\23197\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\23197\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\23197\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\23197\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\23197\\.conda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:151\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "#eval\n",
    "my_alexnet.to(device)\n",
    "my_alexnet.eval()\n",
    "for image,label in test_dataloader:\n",
    "    for idx, (img,label) in enumerate(train_dataloader):\n",
    "        images = img.to(device)\n",
    "        labels = label.to(device)\n",
    "        output = my_alexnet(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
